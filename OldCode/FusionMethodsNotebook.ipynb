{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions Defined.\n",
      "Date-Time:  2023-10-26_15-41\n",
      "Successfully opened gamma data!\n",
      "Successfully opened proton data!\n",
      "Shape of Tel1:  (20000,)\n",
      "Shape of Tel2:  (20000,)\n",
      "Shape of Tel3:  (20000,)\n",
      "Shape of Tel4:  (20000,)\n",
      "Shape of Labels:  (20000,)\n",
      "Labels:  [1 1 1 ... 0 0 0]\n",
      "/home/hanneswarnhofer/ECAP_HiWi_WorkingDirectory\n",
      "[19354 17964  8960 11023 17806 11529 13438  3137 17126  1947]\n",
      "Start Mapping...\n",
      "... Finished Mapping\n",
      "Shape of mapped_images_1:  (5000, 41, 41, 1)\n",
      "Shape of mapped_images:  (4, 5000, 41, 41, 1)\n",
      "New shape of mapped_images:  (5000, 4, 41, 41)\n",
      "New shape of mapped_labels:  (5000, 1)\n",
      "5000  events with 4 images each are available \n",
      "\n",
      "Shape of 'event_labels':  (5000, 1)\n",
      "Shape of 'peak_times':  (5000, 4, 41, 41, 1) \n",
      "\n",
      "[ True  True False  True  True  True  True False False  True]\n",
      "Split into Training and Test Data\n",
      "Train data shape: (4023, 4, 41, 41, 1) --> 80.46 %\n",
      "Test data shape: (977, 4, 41, 41, 1) --> 19.54 %\n",
      "Train labels shape: (4023, 1)\n",
      "Test labels shape: (977, 1)\n",
      "Train data 1 shape: (4023, 41, 41, 1)\n",
      "Train labels 1 shape: (4023, 41, 41, 1)\n",
      "Test data 1 shape: (977, 41, 41, 1)\n",
      "Test labels 1 shape: (977, 41, 41, 1)\n",
      "Test data 1: [[[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]]\n",
      "Plotting Example Event. Event Nr:  4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min. and Max. Value for Image 1:  0.0  -  0.0 . Sum:  0.0\n",
      "Min. and Max. Value for Image 2:  0.0  -  0.0 . Sum:  0.0\n",
      "Min. and Max. Value for Image 3:  0.0  -  25.912879943847656 . Sum:  304.0083541208878\n",
      "Min. and Max. Value for Image 4:  0.0  -  17.71670913696289 . Sum:  258.1585566941649\n",
      "Plotting Example Event. Event Nr:  4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min. and Max. Value for Image 1:  0.0  -  21.499099731445312 . Sum:  364.676172173582\n",
      "Min. and Max. Value for Image 2:  0.0  -  0.0 . Sum:  0.0\n",
      "Min. and Max. Value for Image 3:  0.0  -  20.944557189941406 . Sum:  250.7014093361795\n",
      "Min. and Max. Value for Image 4:  0.0  -  61.57244873046875 . Sum:  624.0711559006013\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tables\n",
    "import tables\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import random\n",
    "\n",
    "import fnmatch\n",
    "import os\n",
    "#import h5\n",
    "import glob\n",
    "import pickle\n",
    "import sys\n",
    "import argparse\n",
    "import h5py\n",
    "import os.path\n",
    "import inspect\n",
    "import json\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "from ctapipe.io import EventSource\n",
    "from ctapipe import utils\n",
    "from ctapipe.instrument.camera import CameraGeometry\n",
    "\n",
    "from dl1_data_handler.reader import DL1DataReader\n",
    "from dl1_data_handler.image_mapper import ImageMapper\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras import layers, models, callbacks, optimizers, regularizers\n",
    "from tensorflow.keras.layers import Input, Concatenate, concatenate, Dense,Lambda,Reshape,Embedding, Conv2D, Conv3D, MaxPooling2D, MaxPooling3D, Flatten, Dropout, ConvLSTM2D, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "\n",
    "class DataManager():\n",
    "    \"\"\" Data class used to manage the HDF5 data files (simulations + Auger data).\n",
    "        data_path: data_path of HDF5 file, (hint: use blosc compression to ensure adequate decompression speed,\n",
    "        to mitigate training bottleneck due to a slow data pipeline)\n",
    "        params:\n",
    "            data_path = path to HDF5 datset\n",
    "        optional params:\n",
    "            stats: data statistics (stats.json - needed for scaling the dataset)\n",
    "            tasks: list of tasks to be included (default: ['axis', 'core', 'energy', 'xmax'])\n",
    "            generator_fn: generator function used for looping over data, generator function needs to have indices and\n",
    "                          shuffle args.\n",
    "            ad_map_fn: \"advanced mapping function\" the function used to map the final dataset. Here an additional\n",
    "                       preprocessing can be implemented which is mapped during training on the\n",
    "                       cpu (based on tf.data.experimental.map_and_batch)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_path, stats=None, tasks=['axis', 'impact', 'energy', 'classification']):\n",
    "        ''' init of DataManager class, to manage simulated (CORSIKA/Offline) and measured dataset '''\n",
    "        current_timestamp = int(time.time())\n",
    "        np.random.seed(current_timestamp)\n",
    "        self.data_path = data_path\n",
    "\n",
    "    def open_ipython(self):\n",
    "        from IPython import embed\n",
    "        embed()\n",
    "\n",
    "    @property\n",
    "    def is_data(self):\n",
    "        return self.type == \"Data\"\n",
    "\n",
    "    @property\n",
    "    def is_mc(self):\n",
    "        return self.type == \"MC\"\n",
    "\n",
    "    def get_h5_file(self):\n",
    "        return h5py.File(self.data_path, \"r\")\n",
    "\n",
    "    def walk_tree(self, details=True):\n",
    "        \"\"\" Draw the tree of yout HDF5 file to see the hierachy of your dataset\n",
    "            params: detail(activate details to see shapes and used compression ops, Default: True)\n",
    "        \"\"\"\n",
    "\n",
    "        def walk(file, iter_str=''):\n",
    "            try:\n",
    "                keys = file.keys()\n",
    "            except AttributeError:\n",
    "                keys = []\n",
    "\n",
    "            for key in keys:\n",
    "                try:\n",
    "                    if details:\n",
    "                        file[key].dtype\n",
    "                        print(iter_str + str(file[key]))\n",
    "                    else:\n",
    "                        print(iter_str + key)\n",
    "                except AttributeError:\n",
    "                    print(iter_str + key)\n",
    "                    walk(file[key], \"   \" + iter_str)\n",
    "\n",
    "        with h5py.File(self.data_path, \"r\") as file:\n",
    "            print(\"filename:\", file.filename)\n",
    "            for key in file.keys():\n",
    "                print(' - ' + key)\n",
    "                walk(file[key], iter_str='   - ')\n",
    "\n",
    "    def extract_info(self, path):\n",
    "        with self.get_h5_file() as f:\n",
    "            data = f[path]\n",
    "            y = np.stack(data[:].tolist())\n",
    "\n",
    "        return {k: y[:, i] for i, k in enumerate(data.dtype.names)}, dict(data.dtype.descr)\n",
    "\n",
    "    def make_mc_data(self):\n",
    "        return self.extract_info(\"simulation/event/subarray/shower\")\n",
    "\n",
    "class MyGenerator(keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self,images_1,images_2,images_3,images_4,labels,batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        self.images_1 = images_1\n",
    "        self.images_2 = images_2\n",
    "        self.images_3 = images_3\n",
    "        self.images_4 = images_4\n",
    "        self.labels = labels\n",
    "        self.sample_count = len(labels[:])\n",
    "        self.batch_count = int(self.sample_count/self.batch_size)\n",
    "        self.current_batch = 0\n",
    "        self.index = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.batch_count\n",
    "\n",
    "\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        idx_low  = self.current_batch*self.batch_size\n",
    "        idx_high = (self.current_batch+1)*self.batch_size\n",
    "        X = np.array([self.images_1[idx_low:idx_high],self.images_2[idx_low:idx_high],self.images_3[idx_low:idx_high],self.images_4[idx_low:idx_high]])\n",
    "        y = np.array(self.labels[idx_low:idx_high])\n",
    "\n",
    "        self.current_batch +=1 \n",
    "        self.data = (X,y)\n",
    "\n",
    "        return self.data\n",
    "        \n",
    "    ''' \n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        idx_low  = self.current_batch*self.batch_size\n",
    "        idx_high = (self.current_batch+1)*self.batch_size\n",
    "        images_batch_1 = self.images_1[idx_low:idx_high]\n",
    "        images_batch_2 = self.images_2[idx_low:idx_high]\n",
    "        images_batch_3 = self.images_3[idx_low:idx_high]\n",
    "        images_batch_4 = self.images_4[idx_low:idx_high]\n",
    "\n",
    "        labels_batch = np.array(self.labels[idx_low:idx_high])\n",
    "\n",
    "        # Assuming your images are of shape (41, 41, 1)\n",
    "        images_batch_1 = np.expand_dims(images_batch_1, axis=-1)\n",
    "        images_batch_2 = np.expand_dims(images_batch_2, axis=-1)\n",
    "        images_batch_3 = np.expand_dims(images_batch_3, axis=-1)\n",
    "        images_batch_4 = np.expand_dims(images_batch_4, axis=-1)\n",
    "\n",
    "        self.current_batch +=1 \n",
    "        self.data = (np.array([images_batch_1, images_batch_2, images_batch_3, images_batch_4]), labels_batch)\n",
    "\n",
    "        # MAYBE CHECK: X = np.array([...]) and y = labels_batch\n",
    "\n",
    "        return self.data\n",
    "    '''\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.index >= self.sample_count:\n",
    "            raise StopIteration\n",
    "        result = self.__getitem__(self.index) \n",
    "        self.index += 1\n",
    "        return result\n",
    "\n",
    "    def plot_batch(self, event_nr=100):\n",
    "        print(np.shape(self.images_1))\n",
    "        print(np.shape(self.images_1[event_nr]))\n",
    "        image_batch_1 = self.images_1\n",
    "        image_batch_2 = self.images_2\n",
    "        image_batch_3 = self.images_3\n",
    "        image_batch_4 = self.images_4\n",
    "        label_batch = self.labels\n",
    "        plot_image_2by2(image_batch_1,image_batch_2,image_batch_3,image_batch_4, labels=label_batch, event_nr=event_nr,string=\"generator\")\n",
    "\n",
    "    def __shape__(self):\n",
    "        print(\"Shape of self.images1: \",np.shape(self.images_1))\n",
    "        print(\"Shape of first event: \",np.shape(self.images_1[0]))\n",
    "\n",
    "    def reset_counters(self): \n",
    "        self.current_batch = 0 \n",
    "\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        self.reset_counters()\n",
    "\n",
    "class OnEpochBegin(keras.callbacks.Callback): # Callback class called on epoch begin to reset counters\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        training_generator.reset_counters()\n",
    "        testing_generator.reset_counters()\n",
    "        print(\"Epoch Begin\")\n",
    "\n",
    "\n",
    "def re_index_ct14(image):\n",
    "    return image[5:, :, :]\n",
    "\n",
    "def make_hess_geometry(file=None):\n",
    "    # quick fix for dl1 data handler to circumvent to use ctapipe\n",
    "    if file is None:\n",
    "        with open(os.path.join(os.getcwd(), \"geometry2d3.json\")) as f: \n",
    "            attr_dict = json.load(f)\n",
    "\n",
    "        data_ct14 = attr_dict[\"ct14_geo\"]\n",
    "        data_ct5 = attr_dict[\"ct5_geo\"]\n",
    "    else:\n",
    "        data_ct14 = file[\"configuration/instrument/telescope/camera/geometry_0\"][:].tolist()\n",
    "        data_ct5 = file[\"configuration/instrument/telescope/camera/geometry_1\"][:].tolist()\n",
    "\n",
    "    class Geometry():\n",
    "        def __init__(self, data):\n",
    "            self.pix_id, self.pix_x, self.pix_y, self.pix_area = np.stack(data).T.astype(np.float32)\n",
    "            self.pos_x = self.pix_x\n",
    "            self.pos_y = self.pix_y\n",
    "\n",
    "        def get_pix_pos(self):\n",
    "            return np.column_stack([self.pix_x, self.pix_y]).T\n",
    "\n",
    "    return Geometry(data_ct14), Geometry(data_ct5)\n",
    "\n",
    "def get_current_path():\n",
    "    filename = inspect.getframeinfo(inspect.currentframe()).filename\n",
    "    return os.path.dirname(os.path.abspath(filename))\n",
    "\n",
    "def rotate(pix_pos, rotation_angle=0):\n",
    "    rotation_angle = rotation_angle * np.pi / 180.0\n",
    "    rotation_matrix = np.matrix([[np.cos(rotation_angle), -np.sin(rotation_angle)],\n",
    "                                [np.sin(rotation_angle), np.cos(rotation_angle)], ], dtype=float)\n",
    "\n",
    "    pixel_positions = np.squeeze(np.asarray(np.dot(rotation_matrix, pix_pos)))\n",
    "    return pixel_positions\n",
    "\n",
    "def plot_image_2by2(train_data,event_nr,labels,string,dt):\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    print(\"Plotting Example Event. Event Nr: \", event_nr)\n",
    "\n",
    "    image1 = train_data[:,0,:,:] \n",
    "    image2 = train_data[:,1,:,:] \n",
    "    image3 = train_data[:,2,:,:] \n",
    "    image4 = train_data[:,3,:,:] \n",
    "\n",
    "    pltimage1 = image1[event_nr]\n",
    "    pltimage2 = image2[event_nr]\n",
    "    pltimage3 = image3[event_nr]\n",
    "    pltimage4 = image4[event_nr]\n",
    "\n",
    "    fig, ax = plt.subplots(2,2)\n",
    "\n",
    "    im1 = ax[0,0].imshow(pltimage1[:,:,0], cmap='viridis',vmin=0)\n",
    "    im2 = ax[0,1].imshow(pltimage2[:,:,0], cmap='viridis',vmin=0)\n",
    "    im3 = ax[1,0].imshow(pltimage3[:,:,0], cmap='viridis',vmin=0)\n",
    "    im4 = ax[1,1].imshow(pltimage4[:,:,0], cmap='viridis',vmin=0)\n",
    "\n",
    "    cbar1 = fig.colorbar(im1, ax=ax[0, 0], orientation='vertical')\n",
    "    cbar2 = fig.colorbar(im2, ax=ax[0, 1], orientation='vertical')\n",
    "    cbar3 = fig.colorbar(im3, ax=ax[1, 0], orientation='vertical')\n",
    "    cbar4 = fig.colorbar(im4, ax=ax[1, 1], orientation='vertical')\n",
    "\n",
    "\n",
    "    label1 = labels[event_nr].ravel()[0]\n",
    "    label2 = labels[event_nr].ravel()[1]\n",
    "    label3 = labels[event_nr].ravel()[2]\n",
    "    label4 = labels[event_nr].ravel()[3]\n",
    "\n",
    "    str_label1 = '{}'.format(label1)\n",
    "    str_label2 = '{}'.format(label2)\n",
    "    str_label3 = '{}'.format(label3)\n",
    "    str_label4 = '{}'.format(label4)\n",
    "\n",
    "    ax[0, 0].text(0.05, 0.95, str_label1, transform=ax[0, 0].transAxes, color='white', fontsize=12, ha='center', va='center', bbox=dict(facecolor='black', alpha=0.7))\n",
    "    ax[0, 1].text(0.05, 0.95, str_label2, transform=ax[0, 1].transAxes, color='white', fontsize=12, ha='center', va='center', bbox=dict(facecolor='black', alpha=0.7))\n",
    "    ax[1, 0].text(0.05, 0.95, str_label3, transform=ax[1, 0].transAxes, color='white', fontsize=12, ha='center', va='center', bbox=dict(facecolor='black', alpha=0.7))\n",
    "    ax[1, 1].text(0.05, 0.95, str_label4, transform=ax[1, 1].transAxes, color='white', fontsize=12, ha='center', va='center', bbox=dict(facecolor='black', alpha=0.7))\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Min. and Max. Value for Image 1: \", np.min(pltimage1), \" - \" , np.max(pltimage1) , \". Sum: \", np.sum(pltimage1))\n",
    "    print(\"Min. and Max. Value for Image 2: \", np.min(pltimage2), \" - \" , np.max(pltimage2), \". Sum: \", np.sum(pltimage2))\n",
    "    print(\"Min. and Max. Value for Image 3: \", np.min(pltimage3), \" - \" , np.max(pltimage3), \". Sum: \", np.sum(pltimage3))\n",
    "    print(\"Min. and Max. Value for Image 4: \", np.min(pltimage4), \" - \" , np.max(pltimage4), \". Sum: \", np.sum(pltimage4))\n",
    "\n",
    "    #str_evnr = '{}'.format(event_nr)\n",
    "    #name = \"Test_images/Test_figure_evnr_\" + str_evnr + \"_\" + string + \"_\" + dt + \".png\"\n",
    "    #fig.savefig(name)\n",
    "\n",
    "print(\"Functions Defined.\")\n",
    "\n",
    "'''\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-e\", \"--epochs\", type=int)\n",
    "parser.add_argument(\"-b\", \"--batch_size\", type=int)\n",
    "parser.add_argument(\"-r\", \"--rate\", type=float)\n",
    "parser.add_argument(\"-reg\", \"--regulization\", type=float)\n",
    "parser.add_argument(\"-t\", \"--threshold\", type=float)\n",
    "parser.add_argument(\"-c\", \"--cut\", type=int)\n",
    "parser.add_argument(\"-ne\", \"--numevents\", type=int)\n",
    "\n",
    "args = parser.parse_args()\n",
    "num_epochs = args.epochs\n",
    "batch_size = args.batch_size\n",
    "rate = args.rate\n",
    "reg = args.regulization\n",
    "sum_threshold = args.threshold\n",
    "cut_nonzero = args.cut\n",
    "num_events = args.numevents\n",
    "'''\n",
    "# Define the appendix to the file, for being able to specify some general changes in the model structure and trace back the changes when comparing the results of t´different models\n",
    "fnr = \"FusionMethods\" \n",
    "\n",
    "current_datetime = datetime.now()\n",
    "formatted_datetime = current_datetime.strftime(\"%Y-%m-%d_%H-%M\")\n",
    "print(\"Date-Time: \", formatted_datetime)\n",
    "\n",
    "num_events = 5000\n",
    "amount = int(num_events * 2)\n",
    "filePath_gamma=\"../../../mnt/c/Users/hanne/Desktop/Studium Physik/ECAP_HiWi_CNN/ECAP_HiWi_WorkingDirectory/phase2d3_timeinfo_gamma_diffuse_hybrid_preselect_20deg_0deg.h5\"\n",
    "#filePath_gamma = \"../../../../wecapstor1/caph/mppi111h/old_dataset/phase2d3_timeinfo_gamma_diffuse_hybrid_preselect_20deg_0deg.h5\"\n",
    "#filePath_gamma = \"../../../../wecapstor1/caph/mppi111h/new_sims/dnn/gamma_diffuse_noZBDT_noLocDist_hybrid_v2.h5\"\n",
    "\n",
    "filePath_proton=\"../../../mnt/c/Users/hanne/Desktop/Studium Physik/ECAP_HiWi_CNN/ECAP_HiWi_WorkingDirectory/phase2d3_timeinfo_proton_hybrid_preselect_20deg_0deg.h5\"\n",
    "#filePath_proton = \"../../../../wecapstor1/caph/mppi111h/old_dataset/phase2d3_timeinfo_proton_hybrid_preselect_20deg_0deg.h5\"\n",
    "#filePath_proton=\"../../../../wecapstor1/caph/mppi111h/new_sims/dnn/proton_noZBDT_noLocDist_hybrid_v2.h5\"\n",
    "\n",
    "dm_gamma = DataManager(filePath_gamma)\n",
    "f_g = dm_gamma.get_h5_file()\n",
    "\n",
    "if num_events >= len(f_g[\"dl1/event/telescope/images/tel_001\"][:]) : num_events = len(f_g[\"dl1/event/telescope/images/tel_001\"][:]) - 2\n",
    "if amount >= len(f_g[\"dl1/event/telescope/images/tel_001\"][:]) : amount = len(f_g[\"dl1/event/telescope/images/tel_001\"][:]) - 1\n",
    "\n",
    "tel1g_raw = f_g[\"dl1/event/telescope/images/tel_001\"][0:amount]\n",
    "tel2g_raw = f_g[\"dl1/event/telescope/images/tel_002\"][0:amount]\n",
    "tel3g_raw = f_g[\"dl1/event/telescope/images/tel_003\"][0:amount]\n",
    "tel4g_raw = f_g[\"dl1/event/telescope/images/tel_004\"][0:amount]\n",
    "#tel5g_raw = f_g[\"dl1/event/telescope/images/tel_005\"][0:amount]\n",
    "\n",
    "print(\"Successfully opened gamma data!\")\n",
    "\n",
    "labelsg = np.stack([data[2] for data in tel1g_raw])\n",
    "labelsg_ones = np.ones_like(labelsg)\n",
    "\n",
    "f_g.close()\n",
    "\n",
    "dm_proton = DataManager(filePath_proton)\n",
    "f_p = dm_proton.get_h5_file()\n",
    "\n",
    "tel1p_raw = f_p[\"dl1/event/telescope/images/tel_001\"][0:amount]\n",
    "tel2p_raw = f_p[\"dl1/event/telescope/images/tel_002\"][0:amount]\n",
    "tel3p_raw = f_p[\"dl1/event/telescope/images/tel_003\"][0:amount]\n",
    "tel4p_raw = f_p[\"dl1/event/telescope/images/tel_004\"][0:amount]\n",
    "#tel5p_raw = f_p[\"dl1/event/telescope/images/tel_005\"][0:amount]\n",
    "\n",
    "print(\"Successfully opened proton data!\")\n",
    "\n",
    "labelsp = np.stack([data[2] for data in tel1p_raw])\n",
    "labelsp_zeros = np.zeros_like(labelsp)\n",
    "\n",
    "tel1 = np.concatenate((tel1g_raw,tel1p_raw),axis=0)\n",
    "tel2 = np.concatenate((tel2g_raw,tel2p_raw),axis=0)\n",
    "tel3 = np.concatenate((tel3g_raw,tel3p_raw),axis=0)\n",
    "tel4 = np.concatenate((tel4g_raw,tel4p_raw),axis=0)\n",
    "#tel5 = np.concatenate((tel5g_raw,tel5p_raw),axis=0)\n",
    "labels = np.concatenate((labelsg_ones,labelsp_zeros),axis=0)\n",
    "\n",
    "del tel1g_raw\n",
    "del tel2g_raw\n",
    "del tel3g_raw\n",
    "del tel4g_raw\n",
    "\n",
    "del tel1p_raw\n",
    "del tel2p_raw\n",
    "del tel3p_raw\n",
    "del tel4p_raw\n",
    "\n",
    "f_p.close()\n",
    "\n",
    "del labelsp\n",
    "del labelsg\n",
    "del labelsp_zeros\n",
    "del labelsg_ones\n",
    "\n",
    "print(\"Shape of Tel1: \",np.shape(tel1))\n",
    "print(\"Shape of Tel2: \",np.shape(tel2))\n",
    "print(\"Shape of Tel3: \",np.shape(tel3))\n",
    "print(\"Shape of Tel4: \",np.shape(tel4))\n",
    "#print(\"Shape of Tel5: \",np.shape(tel5))\n",
    "print(\"Shape of Labels: \",np.shape(labels))\n",
    "print(\"Labels: \",labels)\n",
    "\n",
    "geo_ct14, geo_ct5 = make_hess_geometry()\n",
    "print(os.getcwd())\n",
    "ct_14_mapper = ImageMapper(camera_types=[\"HESS-I\"], pixel_positions={\"HESS-I\": rotate(geo_ct14.get_pix_pos())}, mapping_method={\"HESS-I\": \"axial_addressing\"})\n",
    "#ct_5_mapper = ImageMapper(camera_types=[\"HESS-II\"], pixel_positions={\"HESS-II\": rotate(geo_ct5.get_pix_pos())}, mapping_method={\"HESS-II\": \"axial_addressing\"})\n",
    "\n",
    "mapped_images_1 = np.empty((num_events, 41,41,1))\n",
    "mapped_images_2 = np.empty((num_events, 41,41,1))\n",
    "mapped_images_3 = np.empty((num_events, 41,41,1))\n",
    "mapped_images_4 = np.empty((num_events, 41,41,1))\n",
    "#mapped_images_4 = np.empty((num_events, 41,41,1))\n",
    "mapped_labels = np.empty(num_events)\n",
    "\n",
    "length = num_events\n",
    "max_value = len(tel1)\n",
    "random_list = np.random.randint(max_value, size=length)\n",
    "image_nr = 0\n",
    "\n",
    "print(random_list[0:10])\n",
    "\n",
    "cut_nonzero = 2\n",
    "threshold_value = 0.0001  # Adjust this threshold value as needed\n",
    "\n",
    "print(\"Start Mapping...\")\n",
    "for event_nr in random_list:\n",
    "\n",
    "\n",
    "    \n",
    "    image_1 = ct_14_mapper.map_image(tel1[event_nr][3][:, np.newaxis], 'HESS-I')\n",
    "    image_2 = ct_14_mapper.map_image(tel2[event_nr][3][:, np.newaxis], 'HESS-I')\n",
    "    image_3 = ct_14_mapper.map_image(tel3[event_nr][3][:, np.newaxis], 'HESS-I')   \n",
    "    image_4 = ct_14_mapper.map_image(tel4[event_nr][3][:, np.newaxis], 'HESS-I')\n",
    "    #image_5 = ct_5_mapper.map_image(tel5[event_nr][3][:, np.newaxis], 'HESS-II')   \n",
    "\n",
    "    # Apply threshold on the sum of pixel values\n",
    "    #sum_threshold = 60  # Adjust this value to your desired threshold\n",
    "    sum_threshold = 60 #args.threshold\n",
    "\n",
    "    if np.sum(image_1) < sum_threshold:\n",
    "        image_1[:] = 0\n",
    "    if np.sum(image_2) < sum_threshold:\n",
    "        image_2[:] = 0\n",
    "    if np.sum(image_3) < sum_threshold:\n",
    "        image_3[:] = 0\n",
    "    if np.sum(image_4) < sum_threshold:\n",
    "        image_4[:] = 0\n",
    "     \n",
    "    # Set all pixels lower than the threshold value to zero\n",
    "    image_1[image_1 < threshold_value] = 0\n",
    "    image_2[image_2 < threshold_value] = 0\n",
    "    image_3[image_3 < threshold_value] = 0\n",
    "    image_4[image_4 < threshold_value] = 0\n",
    "    #image_5[image_5 < threshold_value] = 0\n",
    "\n",
    "    non_zero_count = sum(1 for img in [image_1, image_2, image_3, image_4] if np.sum(img) > 0)\n",
    "    if non_zero_count >= cut_nonzero:\n",
    "        mapped_images_1[image_nr] = image_1\n",
    "        mapped_images_2[image_nr] = image_2\n",
    "        mapped_images_3[image_nr] = image_3\n",
    "        mapped_images_4[image_nr] = image_4\n",
    "        #mapped_images_5[image_nr] = image_5\n",
    "        mapped_labels[image_nr] = labels[event_nr]\n",
    "        image_nr += 1\n",
    "    \n",
    "print(\"... Finished Mapping\")\n",
    "\n",
    "'''\n",
    "print(\"Start Mapping...\")\n",
    "for event_nr in random_list:\n",
    "    mapped_images_1[image_nr] = ct_14_mapper.map_image(tel1[event_nr][3][:, np.newaxis], 'HESS-I')\n",
    "    mapped_images_2[image_nr] = ct_14_mapper.map_image(tel2[event_nr][3][:, np.newaxis], 'HESS-I')\n",
    "    mapped_images_3[image_nr] = ct_14_mapper.map_image(tel3[event_nr][3][:, np.newaxis], 'HESS-I')   \n",
    "    mapped_images_4[image_nr] = ct_14_mapper.map_image(tel4[event_nr][3][:, np.newaxis], 'HESS-I')\n",
    "    mapped_labels[image_nr] = labels[event_nr]\n",
    "    image_nr=image_nr+1\n",
    "print(\"... Finished Mapping\")\n",
    "'''\n",
    "#########################################   MAYBE TRY CONVERTING ALL \"EMPTY\" IMAGES IN SUCH A WAY\n",
    "#########################################   THAT ALL PIXELS BECOME ZERO? IF SUM < 0 -> ALL_PIXELS=0\n",
    "#########################################   \n",
    "\n",
    "\n",
    "mapped_images = np.array([mapped_images_1,mapped_images_2,mapped_images_3,mapped_images_4]) #mapped_images_5])\n",
    "print(\"Shape of mapped_images_1: \",np.shape(mapped_images_1))\n",
    "print(\"Shape of mapped_images: \",np.shape(mapped_images))\n",
    "\n",
    "\n",
    "\n",
    "del tel1\n",
    "del tel2\n",
    "del tel3\n",
    "del tel4\n",
    "del labels\n",
    "\n",
    "del mapped_images_1\n",
    "del mapped_images_2\n",
    "del mapped_images_3\n",
    "del mapped_images_4\n",
    "\n",
    "# Reshape the final array, so it is present in the same way as MoDAII data\n",
    "mapped_images = np.transpose(mapped_images, (1, 0, 2, 3, 4))\n",
    "mapped_images = np.squeeze(mapped_images, axis=-1)\n",
    "mapped_labels = mapped_labels[:,np.newaxis]\n",
    "\n",
    "print(\"New shape of mapped_images: \",np.shape(mapped_images))\n",
    "print(\"New shape of mapped_labels: \",np.shape(mapped_labels))\n",
    "\n",
    "\n",
    "########################################################\n",
    "# START WITH CNN STUFF\n",
    "\n",
    "\n",
    "patience = 5\n",
    "input_shape = (41, 41, 1)\n",
    "#input_shape5 = (72,72,1)\n",
    "pool_size = 2\n",
    "kernel_size = 2\n",
    "\n",
    "# some reshaping for the further use of the timing data in the CNN\n",
    "mapped_images = mapped_images.reshape((*np.shape(mapped_images),1))\n",
    "\n",
    "# overview about the important data array for later usage\n",
    "print(np.shape(mapped_images)[0], \" events with 4 images each are available \\n\")\n",
    "print(\"Shape of 'event_labels': \",np.shape(mapped_labels))\n",
    "print(\"Shape of 'peak_times': \",np.shape(mapped_images),\"\\n\")\n",
    "\n",
    "# split into random training data (80%) and test data (20%)\n",
    "train_data = []\n",
    "test_data = []\n",
    "train_labels = []\n",
    "test_labels = [] \n",
    "\n",
    "#data_dummy = mapped_images\n",
    "\n",
    "random_selection = np.random.rand(np.shape(mapped_images)[0]) <= 0.8\n",
    "\n",
    "\n",
    "train_data.append(mapped_images[random_selection])\n",
    "test_data.append(mapped_images[~random_selection])\n",
    "train_labels.append(mapped_labels[random_selection])\n",
    "test_labels.append(mapped_labels[~random_selection])\n",
    "\n",
    "#mapped_images = data_dummy\n",
    "#del data_dummy\n",
    "\n",
    "print(random_selection[0:10])\n",
    "\n",
    "# free some memory space\n",
    "del mapped_images\n",
    "del mapped_labels\n",
    "\n",
    "# convert to numpy array and reshape \n",
    "train_data = np.array(train_data)\n",
    "train_data = train_data.reshape(np.shape(train_data[0]))\n",
    "test_data = np.array(test_data)\n",
    "test_data = test_data.reshape(np.shape(test_data[0]))\n",
    "\n",
    "train_labels = np.array(train_labels)\n",
    "train_labels = train_labels.reshape(np.shape(train_labels[0]))\n",
    "test_labels = np.array(test_labels)\n",
    "test_labels = test_labels.reshape(np.shape(test_labels[0]))\n",
    "\n",
    "train_labels_multishape = np.zeros_like(train_data)\n",
    "test_labels_multishape = np.zeros_like(test_data)\n",
    "\n",
    "len_train = np.shape(train_data)[0]\n",
    "len_test = np.shape(test_data)[0]\n",
    "\n",
    "for i in range(0,len_train):\n",
    "    train_labels_multishape[i,:,:,:] = train_labels[i]\n",
    "\n",
    "for k in range(0,len_test):\n",
    "    test_labels_multishape[k,:,:,:] = test_labels[k]\n",
    "\n",
    "# overvew about the splitting into training and test data\n",
    "print(\"Split into Training and Test Data\")\n",
    "print(\"Train data shape:\", np.shape(train_data) , \"-->\",round(100*len_train/(len_train+len_test),2),\"%\")\n",
    "print(\"Test data shape:\", np.shape(test_data), \"-->\",round(100*len_test/(len_train+len_test),2), \"%\")\n",
    "print(\"Train labels shape:\", np.shape(train_labels))\n",
    "print(\"Test labels shape:\", np.shape(test_labels))\n",
    "\n",
    "# split up different \"telescopes\" for the usage in the seperate single view CNNs (probably in the most long-winded way possible, but lets just ignore that)\n",
    "train_data_1 = train_data[:,0,:,:] \n",
    "train_data_2 = train_data[:,1,:,:] \n",
    "train_data_3 = train_data[:,2,:,:] \n",
    "train_data_4 = train_data[:,3,:,:] \n",
    "#train_data_5 = train_data[:,4,:,:] \n",
    "\n",
    "test_data_1 = test_data[:,0,:,:]\n",
    "test_data_2 = test_data[:,1,:,:]\n",
    "test_data_3 = test_data[:,2,:,:]\n",
    "test_data_4 = test_data[:,3,:,:]\n",
    "#test_data_5 = test_data[:,4,:,:]\n",
    "\n",
    "train_labels_1 = train_labels_multishape[:,0,:,:]\n",
    "train_labels_2 = train_labels_multishape[:,1,:,:]\n",
    "train_labels_3 = train_labels_multishape[:,2,:,:]\n",
    "train_labels_4 = train_labels_multishape[:,3,:,:]\n",
    "#train_labels_5 = train_labels_multishape[:,4,:,:]\n",
    "\n",
    "test_labels_1 = test_labels_multishape[:,0,:,:]\n",
    "test_labels_2 = test_labels_multishape[:,1,:,:]\n",
    "test_labels_3 = test_labels_multishape[:,2,:,:]\n",
    "test_labels_4 = test_labels_multishape[:,3,:,:]\n",
    "#test_labels_5 = test_labels_multishape[:,4,:,:]\n",
    "\n",
    "print(\"Train data 1 shape:\", np.shape(train_data_1))\n",
    "print(\"Train labels 1 shape:\", np.shape(train_labels_1))\n",
    "\n",
    "print(\"Test data 1 shape:\", np.shape(test_data_1))\n",
    "print(\"Test labels 1 shape:\", np.shape(test_labels_1))\n",
    "\n",
    "\n",
    "\n",
    "print(\"Test data 1:\",test_data_1)\n",
    "\n",
    "\n",
    "mean_values = np.mean(train_data,axis=(2,3))\n",
    "max_values = np.amax(train_data,axis=(2,3))\n",
    "\n",
    "mean = np.mean(mean_values)\n",
    "max = np.max(max_values)\n",
    "\n",
    "plot_image_2by2(train_data,4,train_labels_multishape,string=\"train\",dt=formatted_datetime)\n",
    "#plot_image_2by2(train_data,40,train_labels_multishape,string=\"train\",dt=formatted_datetime)\n",
    "#plot_image_2by2(train_data,400,train_labels_multishape,string=\"train\",dt=formatted_datetime)\n",
    "#plot_image_2by2(train_data,4000,train_labels_multishape,string=\"train\",dt=formatted_datetime)\n",
    "\n",
    "plot_image_2by2(test_data,4,test_labels_multishape,string=\"test\",dt=formatted_datetime)\n",
    "#plot_image_2by2(test_data,40,test_labels_multishape,string=\"test\",dt=formatted_datetime)\n",
    "#plot_image_2by2(test_data,400,test_labels_multishape,string=\"test\",dt=formatted_datetime)\n",
    "#plot_image_2by2(test_data,4000,test_labels_multishape,string=\"test\",dt=formatted_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Single-View Model 1\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 80s 626ms/step - loss: 0.7143 - accuracy: 0.4134\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 68s 537ms/step - loss: 0.6947 - accuracy: 0.4094\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 51s 404ms/step - loss: 0.6770 - accuracy: 0.4477\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 52s 409ms/step - loss: 0.6990 - accuracy: 0.4599\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 52s 416ms/step - loss: 0.6848 - accuracy: 0.4549\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 54s 427ms/step - loss: 0.6455 - accuracy: 0.5063\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 54s 430ms/step - loss: 0.6761 - accuracy: 0.5145\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 53s 419ms/step - loss: 0.6834 - accuracy: 0.4862\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 52s 416ms/step - loss: 0.6383 - accuracy: 0.5213\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 51s 403ms/step - loss: 0.6625 - accuracy: 0.5270\n",
      "Training Single-View Model 2\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 75s 588ms/step - loss: 0.7250 - accuracy: 0.4223\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 51s 406ms/step - loss: 0.6781 - accuracy: 0.4536\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 50s 400ms/step - loss: 0.6787 - accuracy: 0.4618\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 51s 406ms/step - loss: 0.6615 - accuracy: 0.4758\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 53s 423ms/step - loss: 0.6654 - accuracy: 0.4889\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 52s 413ms/step - loss: 0.6330 - accuracy: 0.5185\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 51s 406ms/step - loss: 0.6624 - accuracy: 0.5123\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 52s 410ms/step - loss: 0.6513 - accuracy: 0.4974\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 51s 403ms/step - loss: 0.6173 - accuracy: 0.5404\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 52s 413ms/step - loss: 0.5934 - accuracy: 0.5506\n",
      "Training Single-View Model 3\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 53s 411ms/step - loss: 0.7045 - accuracy: 0.4144\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 52s 415ms/step - loss: 0.6629 - accuracy: 0.4633\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 53s 418ms/step - loss: 0.6876 - accuracy: 0.4715\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 52s 411ms/step - loss: 0.6574 - accuracy: 0.4805\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 52s 410ms/step - loss: 0.6566 - accuracy: 0.4934\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 50s 397ms/step - loss: 0.6859 - accuracy: 0.4643\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 49s 391ms/step - loss: 0.6243 - accuracy: 0.5198\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 51s 408ms/step - loss: 0.6564 - accuracy: 0.5061\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 51s 401ms/step - loss: 0.6479 - accuracy: 0.5210\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 49s 390ms/step - loss: 0.6325 - accuracy: 0.5391\n",
      "Training Single-View Model 4\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 52s 407ms/step - loss: 0.7102 - accuracy: 0.4186\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 50s 395ms/step - loss: 0.6894 - accuracy: 0.4447\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 51s 408ms/step - loss: 0.6830 - accuracy: 0.4656\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 52s 411ms/step - loss: 0.6955 - accuracy: 0.4862\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 51s 405ms/step - loss: 0.6433 - accuracy: 0.4942\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 51s 407ms/step - loss: 0.6661 - accuracy: 0.4797\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 50s 398ms/step - loss: 0.6973 - accuracy: 0.4842\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 52s 414ms/step - loss: 0.6801 - accuracy: 0.4879\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 52s 413ms/step - loss: 0.6156 - accuracy: 0.5290\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 55s 436ms/step - loss: 0.5632 - accuracy: 0.5759\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"conv2d_176\" is incompatible with the layer: expected min_ndim=4, found ndim=2. Full shape received: (None, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/hanneswarnhofer/ECAP_HiWi_WorkingDirectory/FusionMethodsNotebook.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/hanneswarnhofer/ECAP_HiWi_WorkingDirectory/FusionMethodsNotebook.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=103'>104</a>\u001b[0m fusion_type \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mfully_connected\u001b[39m\u001b[39m'\u001b[39m  \u001b[39m# Choose 'fully_connected' or 'max_fusion'\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/hanneswarnhofer/ECAP_HiWi_WorkingDirectory/FusionMethodsNotebook.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=105'>106</a>\u001b[0m \u001b[39m# Run multi-view classification\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/hanneswarnhofer/ECAP_HiWi_WorkingDirectory/FusionMethodsNotebook.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=106'>107</a>\u001b[0m predictions \u001b[39m=\u001b[39m run_multiview_classification(single_view_models, test_data, fusion_type)\n",
      "\u001b[1;32m/home/hanneswarnhofer/ECAP_HiWi_WorkingDirectory/FusionMethodsNotebook.ipynb Cell 2\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/hanneswarnhofer/ECAP_HiWi_WorkingDirectory/FusionMethodsNotebook.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=81'>82</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_multiview_classification\u001b[39m(single_view_models, test_data, fusion_type):\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/hanneswarnhofer/ECAP_HiWi_WorkingDirectory/FusionMethodsNotebook.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=82'>83</a>\u001b[0m     fusion_model \u001b[39m=\u001b[39m create_multiview_model(single_view_models, fusion_type)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/hanneswarnhofer/ECAP_HiWi_WorkingDirectory/FusionMethodsNotebook.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=83'>84</a>\u001b[0m     fusion_model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mAdam(), loss\u001b[39m=\u001b[39mbinary_crossentropy, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/hanneswarnhofer/ECAP_HiWi_WorkingDirectory/FusionMethodsNotebook.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=84'>85</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m fusion_model\u001b[39m.\u001b[39mpredict([test_data[:, i, :, :, :] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m4\u001b[39m)])\n",
      "\u001b[1;32m/home/hanneswarnhofer/ECAP_HiWi_WorkingDirectory/FusionMethodsNotebook.ipynb Cell 2\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/hanneswarnhofer/ECAP_HiWi_WorkingDirectory/FusionMethodsNotebook.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=54'>55</a>\u001b[0m     fusion \u001b[39m=\u001b[39m concatenate([model(\u001b[39minput\u001b[39m) \u001b[39mfor\u001b[39;00m model, \u001b[39minput\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(single_view_models, single_view_inputs)])\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/hanneswarnhofer/ECAP_HiWi_WorkingDirectory/FusionMethodsNotebook.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m     x \u001b[39m=\u001b[39m Dropout(\u001b[39m0.2\u001b[39m)(fusion)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/hanneswarnhofer/ECAP_HiWi_WorkingDirectory/FusionMethodsNotebook.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m     x \u001b[39m=\u001b[39m Conv2D(filters\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, kernel_size\u001b[39m=\u001b[39;49m(\u001b[39m2\u001b[39;49m, \u001b[39m2\u001b[39;49m), activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m, padding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msame\u001b[39;49m\u001b[39m'\u001b[39;49m, input_shape\u001b[39m=\u001b[39;49minput_shape)(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/hanneswarnhofer/ECAP_HiWi_WorkingDirectory/FusionMethodsNotebook.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m     x \u001b[39m=\u001b[39m MaxPooling2D(pool_size\u001b[39m=\u001b[39m(\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m), padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msame\u001b[39m\u001b[39m'\u001b[39m)(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/hanneswarnhofer/ECAP_HiWi_WorkingDirectory/FusionMethodsNotebook.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39melif\u001b[39;00m fusion_type \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmax_fusion\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/hanneswarnhofer/ECAP_HiWi_WorkingDirectory/FusionMethodsNotebook.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m     \u001b[39m# Implement max fusion\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/hanneswarnhofer/ECAP_HiWi_WorkingDirectory/FusionMethodsNotebook.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=60'>61</a>\u001b[0m     \u001b[39m# ...\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/keras/engine/input_spec.py:250\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    248\u001b[0m     ndim \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape\u001b[39m.\u001b[39mrank\n\u001b[1;32m    249\u001b[0m     \u001b[39mif\u001b[39;00m ndim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m ndim \u001b[39m<\u001b[39m spec\u001b[39m.\u001b[39mmin_ndim:\n\u001b[0;32m--> 250\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    251\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m{\u001b[39;00minput_index\u001b[39m}\u001b[39;00m\u001b[39m of layer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    252\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mis incompatible with the layer: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    253\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mexpected min_ndim=\u001b[39m\u001b[39m{\u001b[39;00mspec\u001b[39m.\u001b[39mmin_ndim\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    254\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfound ndim=\u001b[39m\u001b[39m{\u001b[39;00mndim\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    255\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFull shape received: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtuple\u001b[39m(shape)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    256\u001b[0m         )\n\u001b[1;32m    257\u001b[0m \u001b[39m# Check dtype.\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[39mif\u001b[39;00m spec\u001b[39m.\u001b[39mdtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"conv2d_176\" is incompatible with the layer: expected min_ndim=4, found ndim=2. Full shape received: (None, 4)"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, LeakyReLU, Dropout, concatenate, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "# Define the model for the single-view CNNs with classification output\n",
    "def create_single_view_cnn_model(input_shape, num_classes, freeze=False):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = Conv2D(filters=200, kernel_size=(3, 3), padding='same')(input_layer)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Conv2D(filters=100, kernel_size=(3, 3), padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Conv2D(filters=50, kernel_size=(3, 3), padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Conv2D(filters=50, kernel_size=(3, 3), padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Conv2D(filters=100, kernel_size=(3, 3), padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Conv2D(filters=100, kernel_size=(3, 3), padding='same')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Conv2D(filters=100, kernel_size=(3, 3), padding='same')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n",
    "    \n",
    "    # Classification output layer\n",
    "    output = Dense(num_classes, activation='sigmoid')(Flatten()(x))  # For binary classification\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "    if freeze:\n",
    "        for layer in model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    return model\n",
    "\n",
    "# Define the model for the combination of the previous CNNs and the final CNN for multi-view classification\n",
    "def create_multiview_model(single_view_models, fusion_type):\n",
    "    input_shapes = [model.input_shape[1:] for model in single_view_models]\n",
    "    single_view_inputs = [Input(shape=input_shape) for input_shape in input_shapes]\n",
    "\n",
    "    # Define the fusion technique (fully connected late fusion or max fusion)\n",
    "    if fusion_type == 'fully_connected':\n",
    "        fusion = concatenate([model(input) for model, input in zip(single_view_models, single_view_inputs)])\n",
    "        x = Dropout(0.2)(fusion)\n",
    "        x = Conv2D(filters=100, kernel_size=(2, 2), activation='relu', padding='same', input_shape=input_shape)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n",
    "    elif fusion_type == 'max_fusion':\n",
    "        # Implement max fusion\n",
    "        # ...\n",
    "        print(\"max_fusion\")\n",
    "    else: \n",
    "        raise ValueError(\"Invalid fusion_type. Use 'fully_connected' or 'max_fusion'.\")\n",
    "\n",
    "    # Additional layers for multi-view classification\n",
    "    # ...\n",
    "\n",
    "    output = Dense(1, activation='sigmoid')(Flatten()(x))  # Binary classification output\n",
    "\n",
    "    model = Model(inputs=single_view_inputs, outputs=output)\n",
    "    return model\n",
    "\n",
    "# Function to train the first part of the model with single-view images\n",
    "def train_single_view_models(single_view_models, train_data, train_labels, num_epochs, batch_size):\n",
    "    for i, model in enumerate(single_view_models):\n",
    "        print(f\"Training Single-View Model {i + 1}\")\n",
    "        model.compile(optimizer=Adam(), loss=binary_crossentropy, metrics=['accuracy'])\n",
    "        model.fit(train_data[:, i, :, :, :], train_labels, epochs=num_epochs, batch_size=batch_size)\n",
    "\n",
    "# Function to run the multi-view model with selected fusion technique\n",
    "def run_multiview_classification(single_view_models, test_data, fusion_type):\n",
    "    fusion_model = create_multiview_model(single_view_models, fusion_type)\n",
    "    fusion_model.compile(optimizer=Adam(), loss=binary_crossentropy, metrics=['accuracy'])\n",
    "    return fusion_model.predict([test_data[:, i, :, :, :] for i in range(4)])\n",
    "\n",
    "# Example usage:\n",
    "input_shape = (41, 41, 1)\n",
    "num_classes = 1  # For binary classification\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "# Create single-view CNN models\n",
    "single_view_models = [create_single_view_cnn_model(input_shape, num_classes, freeze=False) for _ in range(4)]\n",
    "\n",
    "# Train the single-view models\n",
    "train_single_view_models(single_view_models, train_data, train_labels, num_epochs, batch_size)\n",
    "\n",
    "# Freeze the single-view models\n",
    "for model in single_view_models:\n",
    "    model.trainable = False\n",
    "\n",
    "# Select the fusion technique\n",
    "fusion_type = 'fully_connected'  # Choose 'fully_connected' or 'max_fusion'\n",
    "\n",
    "# Run multi-view classification\n",
    "predictions = run_multiview_classification(single_view_models, test_data, fusion_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Single-View Model 1\n",
      "Epoch 1/5\n",
      " 33/126 [======>.......................] - ETA: 18s - loss: 2.1491 - accuracy: 0.4034"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, LeakyReLU, Dropout, concatenate, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "rate=0.2\n",
    "reg = 0.001\n",
    "\n",
    "# Define the common CNN architecture for both single-view and multi-view models\n",
    "def create_shared_cnn_model(input_shape, num_classes, with_output=False):\n",
    "    #input_layer = Input(shape=input_shape)\n",
    "\n",
    "    '''\n",
    "    x = Conv2D(filters=25, kernel_size=(3, 3), padding='same')(input_layer)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Conv2D(filters=30, kernel_size=(3, 3), padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Conv2D(filters=50, kernel_size=(3, 3), padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Conv2D(filters=50, kernel_size=(3, 3), padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Conv2D(filters=100, kernel_size=(3, 3), padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Conv2D(filters=100, kernel_size=(3, 3), padding='same')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    '''\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(filters=25, kernel_size=kernel_size, activation='relu', padding='same',kernel_regularizer=regularizers.l2(reg), input_shape=input_shape,))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size, padding='same'))\n",
    "\n",
    "    model.add(Dropout(rate))\n",
    "    model.add(Conv2D(filters=50, kernel_size=kernel_size, activation='relu', padding='same', kernel_regularizer=regularizers.l2(reg)))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size, padding='same'))\n",
    "\n",
    "    model.add(Dropout(rate))\n",
    "    model.add(Conv2D(filters=50, kernel_size=kernel_size, activation='relu', padding='same',kernel_regularizer=regularizers.l2(reg)))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size, padding='same'))\n",
    "\n",
    "    model.add(Dropout(rate))\n",
    "    model.add(Conv2D(filters=100, kernel_size=kernel_size, activation='relu', padding='same',kernel_regularizer=regularizers.l2(reg)))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size, padding='same'))\n",
    "\n",
    "    if with_output:\n",
    "        model.add(Flatten())\n",
    "        model.add(Dropout(rate))\n",
    "        model.add(Dense(100,activation='relu'))\n",
    "        model.add(Dropout(rate))\n",
    "        model.add(Dense(50,activation='relu'))\n",
    "        model.add(Dropout(rate))\n",
    "        model.add(Dense(num_classes,activation='sigmoid'))\n",
    "\n",
    "    return model\n",
    "\n",
    "# Define the model for the combination of the previous CNNs and the final CNN for multi-view classification\n",
    "def create_multiview_model(single_view_models, fusion_type):\n",
    "    input_shapes = [model.input_shape[1:] for model in single_view_models]\n",
    "    single_view_inputs = [Input(shape=input_shape) for input_shape in input_shapes]\n",
    "\n",
    "    # Define the fusion technique (fully connected late fusion or max fusion)\n",
    "    if fusion_type == 'fully_connected':\n",
    "        fusions = [model(input) for model, input in zip(single_view_models, single_view_inputs)]\n",
    "        fusion = concatenate(fusions)\n",
    "        x = Dropout(0.2)(fusion)\n",
    "        x = Conv2D(filters=100, kernel_size=(2, 2), activation='relu', padding='same')(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Flatten()(x)\n",
    "    elif fusion_type == 'max_fusion':\n",
    "        x = MaxPooling2D(pool_size=(2, 2), padding='same')(concatenate([model(input) for model, input in zip(single_view_models, single_view_inputs)]))\n",
    "        x = Flatten()(x)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid fusion_type. Use 'fully_connected' or 'max_fusion'.\")\n",
    "\n",
    "    output = Dense(1, activation='sigmoid')(x)  # Binary classification output\n",
    "\n",
    "    model = Model(inputs=single_view_inputs, outputs=output)\n",
    "    return model\n",
    "\n",
    "# Function to train the first part of the model with single-view images\n",
    "def train_single_view_models(single_view_models, train_data, train_labels, num_epochs, batch_size):\n",
    "    for i, model in enumerate(single_view_models):\n",
    "        print(f\"Training Single-View Model {i + 1}\")\n",
    "        model.compile(optimizer=Adam(), loss=binary_crossentropy, metrics=['accuracy'])\n",
    "        model.fit(train_data[:, i, :, :, :], train_labels, epochs=num_epochs, batch_size=batch_size)\n",
    "\n",
    "# Function to run the multi-view model with selected fusion technique\n",
    "def run_multiview_classification(single_view_models, test_data, fusion_type):\n",
    "    fusion_model = create_multiview_model(single_view_models, fusion_type)\n",
    "    fusion_model.compile(optimizer=Adam(), loss=binary_crossentropy, metrics=['accuracy'])\n",
    "    return fusion_model.predict([test_data[:, i, :, :, :] for i in range(4)])\n",
    "\n",
    "# Example usage:\n",
    "input_shape = (41, 41, 1)\n",
    "num_classes = 1  # For binary classification\n",
    "num_epochs = 5\n",
    "batch_size = 32\n",
    "\n",
    "# Create single-view CNN models\n",
    "single_view_models = [create_shared_cnn_model(input_shape, num_classes, with_output=True) for _ in range(4)]\n",
    "\n",
    "# Train the single-view models\n",
    "train_single_view_models(single_view_models, train_data, train_labels, num_epochs, batch_size)\n",
    "\n",
    "# Freeze the single-view models\n",
    "for model in single_view_models:\n",
    "    model.trainable = False\n",
    "\n",
    "# Select the fusion technique\n",
    "fusion_type = 'fully_connected'  # Choose 'fully_connected' or 'max_fusion'\n",
    "\n",
    "# Run multi-view\n",
    "predictions_fully_connected = run_multiview_classification(single_view_models, test_data, fusion_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Mean: 0.4282942977918682\n",
      "Overall Max: 11800.990234375\n"
     ]
    }
   ],
   "source": [
    "mean_values = np.mean(train_data,axis=(2,3))\n",
    "max_values = np.amax(train_data,axis=(2,3))\n",
    "\n",
    "mean = np.mean(mean_values)\n",
    "max = np.max(max_values)\n",
    "\n",
    "print(\"Overall Mean:\", mean)\n",
    "print(\"Overall Max:\", max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Lambda, Reshape, Layer\n",
    "\n",
    "rate = 0.1\n",
    "reg = 0.00001\n",
    "\n",
    "\n",
    "#Define the model for the single-view CNNs\n",
    "def create_cnn_model(input_shape,freeze=False):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    Conv1 = Conv2D(filters=200, kernel_size=kernel_size, padding='same',kernel_regularizer=regularizers.l2(reg), input_shape=input_shape,)(input_layer)\n",
    "    LeakyRelu1 = LeakyReLU(alpha=0.1)(Conv1)\n",
    "    MaxPool1 = MaxPooling2D(pool_size=pool_size, padding='same')(LeakyRelu1)\n",
    "\n",
    "    #print(\"Before first Dropout\")\n",
    "\n",
    "    Dropout1 = Dropout(rate)(MaxPool1)\n",
    "    Conv2 = Conv2D(filters=100, kernel_size=kernel_size,padding='same', kernel_regularizer=regularizers.l2(reg))(Dropout1)\n",
    "    LeakyRelu2 = LeakyReLU(alpha=0.1)(Conv2) \n",
    "    MaxPool2 = MaxPooling2D(pool_size=pool_size, padding='same')(LeakyRelu2)\n",
    "\n",
    "    Dropout2 = Dropout(rate)(MaxPool2)\n",
    "    Conv3 = Conv2D(filters=50, kernel_size=kernel_size,padding='same', kernel_regularizer=regularizers.l2(reg))(Dropout2)\n",
    "    LeakyRelu3 = LeakyReLU(alpha=0.1)(Conv3) \n",
    "    MaxPool3 = MaxPooling2D(pool_size=pool_size, padding='same')(LeakyRelu3)\n",
    "\n",
    "    Dropout3 = Dropout(rate)(MaxPool3)\n",
    "    Conv4 = Conv2D(filters=50, kernel_size=kernel_size,padding='same', kernel_regularizer=regularizers.l2(reg))(Dropout3)\n",
    "    LeakyRelu4 = LeakyReLU(alpha=0.1)(Conv4) \n",
    "    MaxPool4 = MaxPooling2D(pool_size=pool_size, padding='same')(LeakyRelu4)\n",
    "\n",
    "    Dropout4 = Dropout(rate)(MaxPool4)\n",
    "    Conv5 = Conv2D(filters=100, kernel_size=kernel_size,padding='same', kernel_regularizer=regularizers.l2(reg))(Dropout4)\n",
    "    LeakyRelu5 = LeakyReLU(alpha=0.1)(Conv5) \n",
    "    MaxPool5 = MaxPooling2D(pool_size=pool_size, padding='same')(LeakyRelu5)\n",
    "\n",
    "    Dropout5 = Dropout(rate)(MaxPool5)\n",
    "    Conv6 = Conv2D(filters=100, kernel_size=kernel_size,padding='same', kernel_regularizer=regularizers.l2(reg))(Dropout5)\n",
    "    MaxPool6 = MaxPooling2D(pool_size=pool_size, padding='same')(Conv6)\n",
    "\n",
    "    Dropout6 = Dropout(rate)(MaxPool6)\n",
    "    Conv7 = Conv2D(filters=100, kernel_size=kernel_size,padding='same', kernel_regularizer=regularizers.l2(reg))(Dropout6)\n",
    "    MaxPool7 = MaxPooling2D(pool_size=pool_size, padding='same')(Conv7)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=MaxPool7)\n",
    "\n",
    "    if freeze:\n",
    "        for layer in model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    return model\n",
    "\n",
    "# Define the model for the combination of the previous CNNs and the final CNN for classification\n",
    "\n",
    "def run_multiview_model_latefusionfc(models, input_shapes, freeze=False):\n",
    "    model_inputs = [Input(shape=input_shape) for input_shape in input_shapes]\n",
    "    single_view_models = [create_cnn_model(input_shape, freeze) for input_shape in input_shapes]\n",
    "\n",
    "    merged = concatenate([model(input) for model, input in zip(single_view_models, model_inputs)])\n",
    "\n",
    "\n",
    "    Dropout1 = Dropout(rate)(merged)\n",
    "    Conv_merged1 = Conv2D(filters=100,kernel_size=[2,2],activation='relu',padding='same',input_shape=input_shape)(Dropout1)\n",
    "    MaxPool_merged1 = MaxPooling2D(pool_size=2,padding='same')(Conv_merged1)\n",
    "\n",
    "    Dropout2 = Dropout(rate)(MaxPool_merged1)\n",
    "    Conv_merged2 = Conv2D(filters=50,kernel_size=[2,2],activation='relu',padding='same',input_shape=input_shape)(Dropout2)\n",
    "    MaxPool_merged2 = MaxPooling2D(pool_size=2,padding='same')(Conv_merged2)\n",
    "\n",
    "    Dropout3 = Dropout(rate)(MaxPool_merged2)\n",
    "    Conv_merged3 = Conv2D(filters=80,kernel_size=[2,2],activation='relu',padding='same',input_shape=input_shape)(Dropout3)\n",
    "    MaxPool_merged3 = MaxPooling2D(pool_size=2,padding='same')(Conv_merged3)\n",
    "\n",
    "    Dropout31 = Dropout(rate)(MaxPool_merged3)\n",
    "    Conv_merged31 = Conv2D(filters=140,kernel_size=[2,2],activation='relu',padding='same',input_shape=input_shape)(Dropout31)\n",
    "    MaxPool_merged31 = MaxPooling2D(pool_size=2,padding='same')(Conv_merged31)\n",
    "\n",
    "    Flat_merged1 = Flatten()(MaxPool_merged31)\n",
    "    Dropout4 = Dropout(rate)(Flat_merged1)\n",
    "    dense_layer_merged1 = Dense(units=100, activation='relu')(Dropout4)\n",
    "\n",
    "    Dropout6 = Dropout(rate)(dense_layer_merged1)\n",
    "    dense_layer_merged3 = Dense(units=1, activation='sigmoid')(Dropout6)\n",
    "\n",
    "    model = Model(inputs=input_shapes, outputs=dense_layer_merged3)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "\n",
    "# Define hyperparameter search space\n",
    "param_dist = {\n",
    "    'optimizer': ['adam', 'sgd', 'rmsprop'],\n",
    "    'rate': [0.25, 0.5, 0.75],\n",
    "    'filters': [16, 32, 64],\n",
    "    'kernel_size': [(3, 3), (4, 4), (5, 5)]\n",
    "}\n",
    "\n",
    "# Wrap the Keras model for use with scikit-learn\n",
    "cnn_model = KerasClassifier(build_fn=create_cnn_model, epochs=num_epochs, batch_size=batch_size, verbose=0)\n",
    "\n",
    "# Perform random search with cross-validation\n",
    "random_search = RandomizedSearchCV(cnn_model, param_distributions=param_dist, n_iter=10, cv=3, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = random_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "63/63 [==============================] - 62s 972ms/step - loss: 1.8538 - accuracy: 0.0021 - val_loss: 0.9329 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "63/63 [==============================] - 54s 858ms/step - loss: 0.8161 - accuracy: 9.2615e-04 - val_loss: 0.7514 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "63/63 [==============================] - 54s 867ms/step - loss: 0.7835 - accuracy: 0.0016 - val_loss: 0.7651 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "63/63 [==============================] - 48s 769ms/step - loss: 0.7776 - accuracy: 0.0070 - val_loss: 0.7380 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "63/63 [==============================] - 45s 708ms/step - loss: 0.7818 - accuracy: 0.0032 - val_loss: 0.7389 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/5\n",
      "63/63 [==============================] - 57s 890ms/step - loss: 1.8027 - accuracy: 0.0071 - val_loss: 0.8330 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "63/63 [==============================] - 45s 712ms/step - loss: 0.8290 - accuracy: 9.8063e-04 - val_loss: 0.7425 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "63/63 [==============================] - 54s 861ms/step - loss: 0.7451 - accuracy: 0.0040 - val_loss: 0.7355 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "63/63 [==============================] - 59s 935ms/step - loss: 0.7453 - accuracy: 0.0072 - val_loss: 0.7574 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "63/63 [==============================] - 64s 1s/step - loss: 0.7690 - accuracy: 0.0027 - val_loss: 0.7387 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/5\n",
      "63/63 [==============================] - 62s 957ms/step - loss: 1.6332 - accuracy: 0.0029 - val_loss: 0.7934 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "63/63 [==============================] - 58s 921ms/step - loss: 0.7296 - accuracy: 0.0067 - val_loss: 0.7132 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "63/63 [==============================] - 56s 891ms/step - loss: 0.7190 - accuracy: 0.0098 - val_loss: 0.7105 - val_accuracy: 9.7199e-04\n",
      "Epoch 4/5\n",
      "63/63 [==============================] - 55s 872ms/step - loss: 0.7177 - accuracy: 0.0105 - val_loss: 0.7199 - val_accuracy: 0.0070\n",
      "Epoch 5/5\n",
      "63/63 [==============================] - 54s 859ms/step - loss: 0.7064 - accuracy: 0.0111 - val_loss: 0.7360 - val_accuracy: 0.0055\n",
      "Epoch 1/5\n",
      "63/63 [==============================] - 64s 1000ms/step - loss: 1.4204 - accuracy: 0.0044 - val_loss: 0.7765 - val_accuracy: 5.1839e-04\n",
      "Epoch 2/5\n",
      "63/63 [==============================] - 58s 929ms/step - loss: 0.7467 - accuracy: 0.0053 - val_loss: 0.7187 - val_accuracy: 0.0046\n",
      "Epoch 3/5\n",
      "63/63 [==============================] - 55s 865ms/step - loss: 0.7219 - accuracy: 0.0053 - val_loss: 0.7182 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "63/63 [==============================] - 55s 877ms/step - loss: 0.7102 - accuracy: 0.0089 - val_loss: 0.7185 - val_accuracy: 0.0021\n",
      "Epoch 5/5\n",
      "63/63 [==============================] - 50s 800ms/step - loss: 0.7058 - accuracy: 0.0092 - val_loss: 0.7001 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "num_epochs = 5\n",
    "batch_size = 64\n",
    "\n",
    "# Create the loss function with from_logits=True\n",
    "loss_fn = BinaryCrossentropy(from_logits=True)\n",
    "early_stopping_callback_1=tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=patience,verbose=1,mode='min')\n",
    "\n",
    "single_view_models = []\n",
    "for i in range(4):\n",
    "    cnn_model = create_cnn_model(input_shape, freeze=False)  # Create a new CNN model\n",
    "    cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    cnn_model.fit(train_data[:, i, :, :], train_labels, epochs=num_epochs, batch_size=batch_size, validation_data=(test_data[:, i, :, :], test_labels), callbacks=[early_stopping_callback_1])\n",
    "\n",
    "    # Append the trained model to the list\n",
    "    single_view_models.append(cnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found unexpected instance while processing input tensors for keras functional model. Expecting KerasTensor which is from tf.keras.Input() or output from keras layer call(). Got: 41",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/hanneswarnhofer/ECAP_HiWi_WorkingDirectory/FusionMethodsNotebook.ipynb Cell 6\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/hanneswarnhofer/ECAP_HiWi_WorkingDirectory/FusionMethodsNotebook.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Step 3: Create the multi-view model using the frozen first CNN models and late fusion layers\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/hanneswarnhofer/ECAP_HiWi_WorkingDirectory/FusionMethodsNotebook.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m input_shapes \u001b[39m=\u001b[39m [input_shape] \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/hanneswarnhofer/ECAP_HiWi_WorkingDirectory/FusionMethodsNotebook.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m model_multi \u001b[39m=\u001b[39m run_multiview_model_latefusionfc(single_view_models, input_shapes, freeze\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/hanneswarnhofer/ECAP_HiWi_WorkingDirectory/FusionMethodsNotebook.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Step 4: Train the multi-view model for multi-view classification\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/hanneswarnhofer/ECAP_HiWi_WorkingDirectory/FusionMethodsNotebook.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m model_multi\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[1;32m/home/hanneswarnhofer/ECAP_HiWi_WorkingDirectory/FusionMethodsNotebook.ipynb Cell 6\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/hanneswarnhofer/ECAP_HiWi_WorkingDirectory/FusionMethodsNotebook.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=81'>82</a>\u001b[0m Dropout6 \u001b[39m=\u001b[39m Dropout(rate)(dense_layer_merged1)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/hanneswarnhofer/ECAP_HiWi_WorkingDirectory/FusionMethodsNotebook.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=82'>83</a>\u001b[0m dense_layer_merged3 \u001b[39m=\u001b[39m Dense(units\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msigmoid\u001b[39m\u001b[39m'\u001b[39m)(Dropout6)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/hanneswarnhofer/ECAP_HiWi_WorkingDirectory/FusionMethodsNotebook.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=84'>85</a>\u001b[0m model \u001b[39m=\u001b[39m Model(inputs\u001b[39m=\u001b[39;49minput_shapes, outputs\u001b[39m=\u001b[39;49mdense_layer_merged3)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/hanneswarnhofer/ECAP_HiWi_WorkingDirectory/FusionMethodsNotebook.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=85'>86</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/tensorflow/python/trackable/base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    206\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/keras/engine/functional.py:157\u001b[0m, in \u001b[0;36mFunctional.__init__\u001b[0;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39m# Check if the inputs contain any intermediate `KerasTensor` (not\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[39m# created by tf.keras.Input()). In this case we need to clone the `Node`\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[39m# and `KerasTensor` objects to mimic rebuilding a new model from new\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39m# inputs.  This feature is only enabled in TF2 not in v1 graph mode.\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mexecuting_eagerly_outside_functions():\n\u001b[1;32m    156\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[0;32m--> 157\u001b[0m         [\n\u001b[1;32m    158\u001b[0m             functional_utils\u001b[39m.\u001b[39mis_input_keras_tensor(t)\n\u001b[1;32m    159\u001b[0m             \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(inputs)\n\u001b[1;32m    160\u001b[0m         ]\n\u001b[1;32m    161\u001b[0m     ):\n\u001b[1;32m    162\u001b[0m         inputs, outputs \u001b[39m=\u001b[39m functional_utils\u001b[39m.\u001b[39mclone_graph_nodes(\n\u001b[1;32m    163\u001b[0m             inputs, outputs\n\u001b[1;32m    164\u001b[0m         )\n\u001b[1;32m    165\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_graph_network(inputs, outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/keras/engine/functional.py:158\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39m# Check if the inputs contain any intermediate `KerasTensor` (not\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[39m# created by tf.keras.Input()). In this case we need to clone the `Node`\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[39m# and `KerasTensor` objects to mimic rebuilding a new model from new\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39m# inputs.  This feature is only enabled in TF2 not in v1 graph mode.\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mexecuting_eagerly_outside_functions():\n\u001b[1;32m    156\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[1;32m    157\u001b[0m         [\n\u001b[0;32m--> 158\u001b[0m             functional_utils\u001b[39m.\u001b[39;49mis_input_keras_tensor(t)\n\u001b[1;32m    159\u001b[0m             \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(inputs)\n\u001b[1;32m    160\u001b[0m         ]\n\u001b[1;32m    161\u001b[0m     ):\n\u001b[1;32m    162\u001b[0m         inputs, outputs \u001b[39m=\u001b[39m functional_utils\u001b[39m.\u001b[39mclone_graph_nodes(\n\u001b[1;32m    163\u001b[0m             inputs, outputs\n\u001b[1;32m    164\u001b[0m         )\n\u001b[1;32m    165\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_graph_network(inputs, outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/keras/engine/functional_utils.py:48\u001b[0m, in \u001b[0;36mis_input_keras_tensor\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Check if tensor is directly generated from `tf.keras.Input`.\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \n\u001b[1;32m     34\u001b[0m \u001b[39mThis check is useful when constructing the functional model, since we will\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39m  ValueError: if the tensor is not a KerasTensor instance.\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m node_module\u001b[39m.\u001b[39mis_keras_tensor(tensor):\n\u001b[0;32m---> 48\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(_KERAS_TENSOR_TYPE_CHECK_ERROR_MSG\u001b[39m.\u001b[39mformat(tensor))\n\u001b[1;32m     49\u001b[0m \u001b[39mreturn\u001b[39;00m tensor\u001b[39m.\u001b[39mnode\u001b[39m.\u001b[39mis_input\n",
      "\u001b[0;31mValueError\u001b[0m: Found unexpected instance while processing input tensors for keras functional model. Expecting KerasTensor which is from tf.keras.Input() or output from keras layer call(). Got: 41"
     ]
    }
   ],
   "source": [
    "# Step 2: Freeze the layers of the first CNN models\n",
    "for model in single_view_models:\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "# Step 3: Create the multi-view model using the frozen first CNN models and late fusion layers\n",
    "input_shapes = [input_shape] * 4\n",
    "model_multi = run_multiview_model_latefusionfc(single_view_models, input_shapes, freeze=True)\n",
    "\n",
    "# Step 4: Train the multi-view model for multi-view classification\n",
    "model_multi.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_multi.fit([test_data[:, i, :, :] for i in range(4)], test_labels, epochs=num_epochs, batch_size=batch_size, validation_data=([test_data[:, i, :, :] for i in range(4)], test_labels), callbacks=[early_stopping_callback_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_88\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_107 (InputLayer)         [(None, 41, 41, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " input_109 (InputLayer)         [(None, 41, 41, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " input_111 (InputLayer)         [(None, 41, 41, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " input_113 (InputLayer)         [(None, 41, 41, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " model_84 (Functional)          (None, 1, 1, 100)    211500      ['input_107[0][0]']              \n",
      "                                                                                                  \n",
      " model_85 (Functional)          (None, 1, 1, 100)    211500      ['input_109[0][0]']              \n",
      "                                                                                                  \n",
      " model_86 (Functional)          (None, 1, 1, 100)    211500      ['input_111[0][0]']              \n",
      "                                                                                                  \n",
      " model_87 (Functional)          (None, 1, 1, 100)    211500      ['input_113[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_13 (Concatenate)   (None, 1, 1, 400)    0           ['model_84[0][0]',               \n",
      "                                                                  'model_85[0][0]',               \n",
      "                                                                  'model_86[0][0]',               \n",
      "                                                                  'model_87[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_521 (Dropout)          (None, 1, 1, 400)    0           ['concatenate_13[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_514 (Conv2D)            (None, 1, 1, 100)    160100      ['dropout_521[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_514 (MaxPooling2  (None, 1, 1, 100)   0           ['conv2d_514[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " dropout_522 (Dropout)          (None, 1, 1, 100)    0           ['max_pooling2d_514[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_515 (Conv2D)            (None, 1, 1, 50)     20050       ['dropout_522[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_515 (MaxPooling2  (None, 1, 1, 50)    0           ['conv2d_515[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " dropout_523 (Dropout)          (None, 1, 1, 50)     0           ['max_pooling2d_515[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_516 (Conv2D)            (None, 1, 1, 80)     16080       ['dropout_523[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_516 (MaxPooling2  (None, 1, 1, 80)    0           ['conv2d_516[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " dropout_524 (Dropout)          (None, 1, 1, 80)     0           ['max_pooling2d_516[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_517 (Conv2D)            (None, 1, 1, 140)    44940       ['dropout_524[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_517 (MaxPooling2  (None, 1, 1, 140)   0           ['conv2d_517[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " flatten_29 (Flatten)           (None, 140)          0           ['max_pooling2d_517[0][0]']      \n",
      "                                                                                                  \n",
      " dropout_525 (Dropout)          (None, 140)          0           ['flatten_29[0][0]']             \n",
      "                                                                                                  \n",
      " dense_61 (Dense)               (None, 100)          14100       ['dropout_525[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_526 (Dropout)          (None, 100)          0           ['dense_61[0][0]']               \n",
      "                                                                                                  \n",
      " dense_62 (Dense)               (None, 1)            101         ['dropout_526[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,101,371\n",
      "Trainable params: 1,101,371\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_89\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_107 (InputLayer)         [(None, 41, 41, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " input_109 (InputLayer)         [(None, 41, 41, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " input_111 (InputLayer)         [(None, 41, 41, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " input_113 (InputLayer)         [(None, 41, 41, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " model_84 (Functional)          (None, 1, 1, 100)    211500      ['input_107[0][0]']              \n",
      "                                                                                                  \n",
      " model_85 (Functional)          (None, 1, 1, 100)    211500      ['input_109[0][0]']              \n",
      "                                                                                                  \n",
      " model_86 (Functional)          (None, 1, 1, 100)    211500      ['input_111[0][0]']              \n",
      "                                                                                                  \n",
      " model_87 (Functional)          (None, 1, 1, 100)    211500      ['input_113[0][0]']              \n",
      "                                                                                                  \n",
      " lambda_11 (Lambda)             (None, 1, 1, 100)    0           ['model_84[0][0]',               \n",
      "                                                                  'model_85[0][0]',               \n",
      "                                                                  'model_86[0][0]',               \n",
      "                                                                  'model_87[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_527 (Dropout)          (None, 1, 1, 100)    0           ['lambda_11[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_518 (Conv2D)            (None, 1, 1, 100)    40100       ['dropout_527[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_518 (MaxPooling2  (None, 1, 1, 100)   0           ['conv2d_518[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " dropout_528 (Dropout)          (None, 1, 1, 100)    0           ['max_pooling2d_518[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_519 (Conv2D)            (None, 1, 1, 50)     20050       ['dropout_528[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_519 (MaxPooling2  (None, 1, 1, 50)    0           ['conv2d_519[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " dropout_529 (Dropout)          (None, 1, 1, 50)     0           ['max_pooling2d_519[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_520 (Conv2D)            (None, 1, 1, 80)     16080       ['dropout_529[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_520 (MaxPooling2  (None, 1, 1, 80)    0           ['conv2d_520[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " dropout_530 (Dropout)          (None, 1, 1, 80)     0           ['max_pooling2d_520[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_521 (Conv2D)            (None, 1, 1, 140)    44940       ['dropout_530[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_521 (MaxPooling2  (None, 1, 1, 140)   0           ['conv2d_521[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " flatten_30 (Flatten)           (None, 140)          0           ['max_pooling2d_521[0][0]']      \n",
      "                                                                                                  \n",
      " dropout_531 (Dropout)          (None, 140)          0           ['flatten_30[0][0]']             \n",
      "                                                                                                  \n",
      " dense_63 (Dense)               (None, 100)          14100       ['dropout_531[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_532 (Dropout)          (None, 100)          0           ['dense_63[0][0]']               \n",
      "                                                                                                  \n",
      " dense_64 (Dense)               (None, 1)            101         ['dropout_532[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 981,371\n",
      "Trainable params: 981,371\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_90\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_107 (InputLayer)         [(None, 41, 41, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " input_109 (InputLayer)         [(None, 41, 41, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " input_111 (InputLayer)         [(None, 41, 41, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " input_113 (InputLayer)         [(None, 41, 41, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " model_84 (Functional)          (None, 1, 1, 100)    211500      ['input_107[0][0]']              \n",
      "                                                                                                  \n",
      " model_85 (Functional)          (None, 1, 1, 100)    211500      ['input_109[0][0]']              \n",
      "                                                                                                  \n",
      " model_86 (Functional)          (None, 1, 1, 100)    211500      ['input_111[0][0]']              \n",
      "                                                                                                  \n",
      " model_87 (Functional)          (None, 1, 1, 100)    211500      ['input_113[0][0]']              \n",
      "                                                                                                  \n",
      " tf.stack_14 (TFOpLambda)       (None, 1, 1, 100, 4  0           ['model_84[0][0]',               \n",
      "                                )                                 'model_85[0][0]',               \n",
      "                                                                  'model_86[0][0]',               \n",
      "                                                                  'model_87[0][0]']               \n",
      "                                                                                                  \n",
      " tf.math.reduce_max_8 (TFOpLamb  (None, 1, 1, 100)   0           ['tf.stack_14[0][0]']            \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " dropout_533 (Dropout)          (None, 1, 1, 100)    0           ['tf.math.reduce_max_8[0][0]']   \n",
      "                                                                                                  \n",
      " conv2d_522 (Conv2D)            (None, 1, 1, 100)    40100       ['dropout_533[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_522 (MaxPooling2  (None, 1, 1, 100)   0           ['conv2d_522[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " dropout_534 (Dropout)          (None, 1, 1, 100)    0           ['max_pooling2d_522[0][0]']      \n",
      "                                                                                                  \n",
      " dense_65 (Dense)               (None, 1, 1, 1)      101         ['dropout_534[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 886,201\n",
      "Trainable params: 886,201\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.conv2d_6), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(1, 1, 4, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "Shape of layer output convolution: KerasTensor(type_spec=TensorSpec(shape=(5,), dtype=tf.int32, name=None), inferred_value=[None, 1, 1, 100, 1], name='tf.compat.v1.shape_4/Shape:0', description=\"created by layer 'tf.compat.v1.shape_4'\")\n",
      "Shape of layer output fused_feature_map: KerasTensor(type_spec=TensorSpec(shape=(5,), dtype=tf.int32, name=None), inferred_value=[None, 1, 1, 100, 1], name='tf.compat.v1.shape_5/Shape:0', description=\"created by layer 'tf.compat.v1.shape_5'\")\n",
      "Shape of layer output Dropout1: KerasTensor(type_spec=TensorSpec(shape=(5,), dtype=tf.int32, name=None), inferred_value=[None, 1, 1, 100, 1], name='tf.compat.v1.shape_6/Shape:0', description=\"created by layer 'tf.compat.v1.shape_6'\")\n",
      "Shape of layer output Conv_merged1: KerasTensor(type_spec=TensorSpec(shape=(5,), dtype=tf.int32, name=None), inferred_value=[None, 1, 1, 100, 100], name='tf.compat.v1.shape_7/Shape:0', description=\"created by layer 'tf.compat.v1.shape_7'\")\n",
      "Shape of layer output MaxPoolmerged1: KerasTensor(type_spec=TensorSpec(shape=(4,), dtype=tf.int32, name=None), inferred_value=[None, 1, 1, 100], name='tf.compat.v1.shape_8/Shape:0', description=\"created by layer 'tf.compat.v1.shape_8'\")\n",
      "Model: \"model_91\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_107 (InputLayer)         [(None, 41, 41, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " input_109 (InputLayer)         [(None, 41, 41, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " input_111 (InputLayer)         [(None, 41, 41, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " input_113 (InputLayer)         [(None, 41, 41, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " model_84 (Functional)          (None, 1, 1, 100)    211500      ['input_107[0][0]']              \n",
      "                                                                                                  \n",
      " model_85 (Functional)          (None, 1, 1, 100)    211500      ['input_109[0][0]']              \n",
      "                                                                                                  \n",
      " model_86 (Functional)          (None, 1, 1, 100)    211500      ['input_111[0][0]']              \n",
      "                                                                                                  \n",
      " model_87 (Functional)          (None, 1, 1, 100)    211500      ['input_113[0][0]']              \n",
      "                                                                                                  \n",
      " tf.stack_15 (TFOpLambda)       (None, 1, 1, 100, 4  0           ['model_84[0][0]',               \n",
      "                                )                                 'model_85[0][0]',               \n",
      "                                                                  'model_86[0][0]',               \n",
      "                                                                  'model_87[0][0]']               \n",
      "                                                                                                  \n",
      " tf.compat.v1.nn.conv2d_6 (TFOp  (None, 1, 1, 100, 1  0          ['tf.stack_15[0][0]']            \n",
      " Lambda)                        )                                                                 \n",
      "                                                                                                  \n",
      " tf.nn.relu_6 (TFOpLambda)      (None, 1, 1, 100, 1  0           ['tf.compat.v1.nn.conv2d_6[0][0]'\n",
      "                                )                                ]                                \n",
      "                                                                                                  \n",
      " dropout_535 (Dropout)          (None, 1, 1, 100, 1  0           ['tf.nn.relu_6[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_523 (Conv2D)            (None, 1, 1, 100, 1  500         ['dropout_535[0][0]']            \n",
      "                                00)                                                               \n",
      "                                                                                                  \n",
      " tf.reshape (TFOpLambda)        (None, 1, 1, 100)    0           ['conv2d_523[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_523 (MaxPooling2  (None, 1, 1, 100)   0           ['tf.reshape[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " dropout_536 (Dropout)          (None, 1, 1, 100)    0           ['max_pooling2d_523[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_524 (Conv2D)            (None, 1, 1, 50)     20050       ['dropout_536[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_524 (MaxPooling2  (None, 1, 1, 50)    0           ['conv2d_524[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " dropout_537 (Dropout)          (None, 1, 1, 50)     0           ['max_pooling2d_524[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_525 (Conv2D)            (None, 1, 1, 80)     16080       ['dropout_537[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_525 (MaxPooling2  (None, 1, 1, 80)    0           ['conv2d_525[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " dropout_538 (Dropout)          (None, 1, 1, 80)     0           ['max_pooling2d_525[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_526 (Conv2D)            (None, 1, 1, 140)    44940       ['dropout_538[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_526 (MaxPooling2  (None, 1, 1, 140)   0           ['conv2d_526[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " flatten_31 (Flatten)           (None, 140)          0           ['max_pooling2d_526[0][0]']      \n",
      "                                                                                                  \n",
      " dropout_539 (Dropout)          (None, 140)          0           ['flatten_31[0][0]']             \n",
      "                                                                                                  \n",
      " dense_66 (Dense)               (None, 100)          14100       ['dropout_539[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_540 (Dropout)          (None, 100)          0           ['dense_66[0][0]']               \n",
      "                                                                                                  \n",
      " dense_67 (Dense)               (None, 1)            101         ['dropout_540[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 941,771\n",
      "Trainable params: 941,771\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Lambda, Reshape, Layer\n",
    "\n",
    "rate = 0.0001\n",
    "reg = 0.00005\n",
    "\n",
    "#Define the model for the single-view CNNs\n",
    "def create_cnn_model(input_shape,freeze=False):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    Conv1 = Conv2D(filters=200, kernel_size=kernel_size, padding='same',kernel_regularizer=regularizers.l2(reg), input_shape=input_shape,)(input_layer)\n",
    "    LeakyRelu1 = LeakyReLU(alpha=0.1)(Conv1)\n",
    "    MaxPool1 = MaxPooling2D(pool_size=pool_size, padding='same')(LeakyRelu1)\n",
    "\n",
    "    #print(\"Before first Dropout\")\n",
    "\n",
    "    Dropout1 = Dropout(rate)(MaxPool1)\n",
    "    Conv2 = Conv2D(filters=100, kernel_size=kernel_size,padding='same', kernel_regularizer=regularizers.l2(reg))(Dropout1)\n",
    "    LeakyRelu2 = LeakyReLU(alpha=0.1)(Conv2) \n",
    "    MaxPool2 = MaxPooling2D(pool_size=pool_size, padding='same')(LeakyRelu2)\n",
    "\n",
    "    Dropout2 = Dropout(rate)(MaxPool2)\n",
    "    Conv3 = Conv2D(filters=50, kernel_size=kernel_size,padding='same', kernel_regularizer=regularizers.l2(reg))(Dropout2)\n",
    "    LeakyRelu3 = LeakyReLU(alpha=0.1)(Conv3) \n",
    "    MaxPool3 = MaxPooling2D(pool_size=pool_size, padding='same')(LeakyRelu3)\n",
    "\n",
    "    Dropout3 = Dropout(rate)(MaxPool3)\n",
    "    Conv4 = Conv2D(filters=50, kernel_size=kernel_size,padding='same', kernel_regularizer=regularizers.l2(reg))(Dropout3)\n",
    "    LeakyRelu4 = LeakyReLU(alpha=0.1)(Conv4) \n",
    "    MaxPool4 = MaxPooling2D(pool_size=pool_size, padding='same')(LeakyRelu4)\n",
    "\n",
    "    Dropout4 = Dropout(rate)(MaxPool4)\n",
    "    Conv5 = Conv2D(filters=100, kernel_size=kernel_size,padding='same', kernel_regularizer=regularizers.l2(reg))(Dropout4)\n",
    "    LeakyRelu5 = LeakyReLU(alpha=0.1)(Conv5) \n",
    "    MaxPool5 = MaxPooling2D(pool_size=pool_size, padding='same')(LeakyRelu5)\n",
    "\n",
    "    Dropout5 = Dropout(rate)(MaxPool5)\n",
    "    Conv6 = Conv2D(filters=100, kernel_size=kernel_size,padding='same', kernel_regularizer=regularizers.l2(reg))(Dropout5)\n",
    "    MaxPool6 = MaxPooling2D(pool_size=pool_size, padding='same')(Conv6)\n",
    "\n",
    "    Dropout6 = Dropout(rate)(MaxPool6)\n",
    "    Conv7 = Conv2D(filters=100, kernel_size=kernel_size,padding='same', kernel_regularizer=regularizers.l2(reg))(Dropout6)\n",
    "    MaxPool7 = MaxPooling2D(pool_size=pool_size, padding='same')(Conv7)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=MaxPool7)\n",
    "\n",
    "    if freeze:\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    return model\n",
    "\n",
    "# Define the model for the combination of the previous CNNs and the final CNN for classification\n",
    "\n",
    "def run_multiview_model(models,inputs):\n",
    "\n",
    "    merged = concatenate(models)\n",
    "\n",
    "    Dropout1 = Dropout(rate)(merged)\n",
    "    Conv_merged1 = Conv2D(filters=100,kernel_size=[2,2],activation='relu',padding='same',input_shape=input_shape)(Dropout1)\n",
    "    MaxPool_merged1 = MaxPooling2D(pool_size=2,padding='same')(Conv_merged1)\n",
    "\n",
    "    Dropout2 = Dropout(rate)(MaxPool_merged1)\n",
    "    Conv_merged2 = Conv2D(filters=50,kernel_size=[2,2],activation='relu',padding='same',input_shape=input_shape)(Dropout2)\n",
    "    MaxPool_merged2 = MaxPooling2D(pool_size=2,padding='same')(Conv_merged2)\n",
    "\n",
    "    Dropout3 = Dropout(rate)(MaxPool_merged2)\n",
    "    Conv_merged3 = Conv2D(filters=80,kernel_size=[2,2],activation='relu',padding='same',input_shape=input_shape)(Dropout3)\n",
    "    MaxPool_merged3 = MaxPooling2D(pool_size=2,padding='same')(Conv_merged3)\n",
    "\n",
    "    Dropout31 = Dropout(rate)(MaxPool_merged3)\n",
    "    Conv_merged31 = Conv2D(filters=140,kernel_size=[2,2],activation='relu',padding='same',input_shape=input_shape)(Dropout31)\n",
    "    MaxPool_merged31 = MaxPooling2D(pool_size=2,padding='same')(Conv_merged31)\n",
    "\n",
    "    Flat_merged1 = Flatten()(MaxPool_merged31)\n",
    "    Dropout4 = Dropout(rate)(Flat_merged1)\n",
    "    dense_layer_merged1 = Dense(units=100, activation='relu')(Dropout4)\n",
    "\n",
    "    Dropout6 = Dropout(rate)(dense_layer_merged1)\n",
    "    dense_layer_merged3 = Dense(units=1, activation='sigmoid')(Dropout6)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=dense_layer_merged3)\n",
    "    return model\n",
    "\n",
    "class CustomFusionLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(CustomFusionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Define your custom variables here\n",
    "        self.conv_weights = self.add_weight(\"conv_weights\", shape=(1, 1, 4, 1), trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Implement your custom operation here\n",
    "        fused_feature_map = tf.nn.conv2d(inputs, self.conv_weights, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "        return tf.nn.relu(fused_feature_map)\n",
    "\n",
    "def run_multiview_model_latefusionmax(models,inputs):\n",
    "\n",
    "    #max_pooled = CustomFusionLayer()(models)  #Lambda(lambda x: tf.reduce_max(x, axis=0), output_shape=input_shape)(models)\n",
    "    max_pooled = Lambda(lambda x: tf.reduce_max(x, axis=0), output_shape=input_shape)(models)\n",
    "    Dropout1 = Dropout(rate)(max_pooled)\n",
    "    Conv_merged1 = Conv2D(filters=100,kernel_size=[2,2],activation='relu',padding='same',input_shape=input_shape)(Dropout1)\n",
    "    MaxPool_merged1 = MaxPooling2D(pool_size=2,padding='same')(Conv_merged1)\n",
    "\n",
    "    Dropout2 = Dropout(rate)(MaxPool_merged1)\n",
    "    Conv_merged2 = Conv2D(filters=50,kernel_size=[2,2],activation='relu',padding='same',input_shape=input_shape)(Dropout2)\n",
    "    MaxPool_merged2 = MaxPooling2D(pool_size=2,padding='same')(Conv_merged2)\n",
    "\n",
    "    Dropout3 = Dropout(rate)(MaxPool_merged2)\n",
    "    Conv_merged3 = Conv2D(filters=80,kernel_size=[2,2],activation='relu',padding='same',input_shape=input_shape)(Dropout3)\n",
    "    MaxPool_merged3 = MaxPooling2D(pool_size=2,padding='same')(Conv_merged3)\n",
    "\n",
    "    Dropout31 = Dropout(rate)(MaxPool_merged3)\n",
    "    Conv_merged31 = Conv2D(filters=140,kernel_size=[2,2],activation='relu',padding='same',input_shape=input_shape)(Dropout31)\n",
    "    MaxPool_merged31 = MaxPooling2D(pool_size=2,padding='same')(Conv_merged31)\n",
    "\n",
    "    Flat_merged1 = Flatten()(MaxPool_merged31)\n",
    "    Dropout4 = Dropout(rate)(Flat_merged1)\n",
    "    dense_layer_merged1 = Dense(units=100, activation='relu')(Dropout4)\n",
    "\n",
    "    Dropout6 = Dropout(rate)(dense_layer_merged1)\n",
    "    dense_layer_merged3 = Dense(units=1, activation='sigmoid')(Dropout6)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=dense_layer_merged3)\n",
    "    return model\n",
    "\n",
    "def run_multiview_model_earlymax(models,inputs):\n",
    "    stacked = tf.stack(models, axis=4)\n",
    "    fused_feature_map = tf.reduce_max(stacked,axis=4)\n",
    "    Dropout1 = Dropout(rate)(fused_feature_map)\n",
    "    Conv_merged1 = Conv2D(filters=100,kernel_size=[2,2],activation='relu',padding='same',input_shape=input_shape)(Dropout1)\n",
    "    MaxPool_merged1 = MaxPooling2D(pool_size=2,padding='same')(Conv_merged1)\n",
    "\n",
    "    '''\n",
    "\n",
    "    Dropout2 = Dropout(rate)(MaxPool_merged1)\n",
    "    Conv_merged2 = Conv2D(filters=50,kernel_size=[2,2],activation='relu',padding='same',input_shape=input_shape)(Dropout2)\n",
    "    MaxPool_merged2 = MaxPooling2D(pool_size=2,padding='same')(Conv_merged2)\n",
    "\n",
    "    Dropout3 = Dropout(rate)(MaxPool_merged2)\n",
    "    Conv_merged3 = Conv2D(filters=80,kernel_size=[2,2],activation='relu',padding='same',input_shape=input_shape)(Dropout3)\n",
    "    MaxPool_merged3 = MaxPooling2D(pool_size=2,padding='same')(Conv_merged3)\n",
    "\n",
    "    Dropout31 = Dropout(rate)(MaxPool_merged3)\n",
    "    Conv_merged31 = Conv2D(filters=140,kernel_size=[2,2],activation='relu',padding='same',input_shape=input_shape)(Dropout31)\n",
    "    MaxPool_merged31 = MaxPooling2D(pool_size=2,padding='same')(Conv_merged31)\n",
    "\n",
    "    Flat_merged1 = Flatten()(MaxPool_merged31)\n",
    "    Dropout4 = Dropout(rate)(Flat_merged1)\n",
    "    dense_layer_merged1 = Dense(units=100, activation='relu')(Dropout4)\n",
    "    '''\n",
    "\n",
    "    Dropout6 = Dropout(rate)(MaxPool_merged1) #(dense_layer_merged1)\n",
    "    dense_layer_merged3 = Dense(units=1, activation='sigmoid')(Dropout6)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=dense_layer_merged3)\n",
    "    return model\n",
    "\n",
    "\n",
    "def run_multiview_model_earlyconv(models,inputs):\n",
    "    stacked = tf.stack(models, axis=4)\n",
    "    # Define a 1x1 convolutional layer with trainable weights\n",
    "    conv_weights = tf.Variable(tf.random.normal([1, 1, 4, 1]), trainable=True)\n",
    "    convolution = tf.nn.conv2d(stacked, conv_weights, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "    layer_output = convolution # Replace this with the specific layer you want to inspect\n",
    "    print(\"Shape of layer output convolution:\", tf.shape(layer_output))\n",
    "\n",
    "    # Apply ReLU activation or any other desired activation function\n",
    "    fused_feature_map = tf.nn.relu(convolution)\n",
    "    layer_output = fused_feature_map # Replace this with the specific layer you want to inspect\n",
    "    print(\"Shape of layer output fused_feature_map:\", tf.shape(layer_output))\n",
    "    #reshaped_tensor = Reshape((1,1,100))(fused_feature_map)\n",
    "    Dropout1 = Dropout(rate)(fused_feature_map) #(reshaped_tensor)\n",
    "    layer_output = Dropout1  # Replace this with the specific layer you want to inspect\n",
    "    print(\"Shape of layer output Dropout1:\", tf.shape(layer_output))\n",
    "    Conv_merged1 = Conv2D(filters=100,kernel_size=[2,2],activation='relu',padding='same',input_shape=input_shape)(Dropout1)\n",
    "    layer_output = Conv_merged1  # Replace this with the specific layer you want to inspect\n",
    "    print(\"Shape of layer output Conv_merged1:\", tf.shape(layer_output))\n",
    "    reshaped_tensor2 = tf.reshape(Conv_merged1,(-1,1,1,100))\n",
    "    MaxPool_merged1 = MaxPooling2D(pool_size=2,padding='same')(reshaped_tensor2) #(Conv_merged1)\n",
    "    layer_output = MaxPool_merged1  # Replace this with the specific layer you want to inspect\n",
    "    print(\"Shape of layer output MaxPoolmerged1:\", tf.shape(layer_output))\n",
    "\n",
    "    Dropout2 = Dropout(rate)(MaxPool_merged1)\n",
    "    Conv_merged2 = Conv2D(filters=50,kernel_size=[2,2],activation='relu',padding='same',input_shape=input_shape)(Dropout2)\n",
    "    MaxPool_merged2 = MaxPooling2D(pool_size=2,padding='same')(Conv_merged2)\n",
    "\n",
    "    Dropout3 = Dropout(rate)(MaxPool_merged2)\n",
    "    Conv_merged3 = Conv2D(filters=80,kernel_size=[2,2],activation='relu',padding='same',input_shape=input_shape)(Dropout3)\n",
    "    MaxPool_merged3 = MaxPooling2D(pool_size=2,padding='same')(Conv_merged3)\n",
    "\n",
    "    Dropout31 = Dropout(rate)(MaxPool_merged3)\n",
    "    Conv_merged31 = Conv2D(filters=140,kernel_size=[2,2],activation='relu',padding='same',input_shape=input_shape)(Dropout31)\n",
    "    MaxPool_merged31 = MaxPooling2D(pool_size=2,padding='same')(Conv_merged31)\n",
    "\n",
    "    Flat_merged1 = Flatten()(MaxPool_merged31)\n",
    "    Dropout4 = Dropout(rate)(Flat_merged1)\n",
    "    dense_layer_merged1 = Dense(units=100, activation='relu')(Dropout4)\n",
    "\n",
    "    Dropout6 = Dropout(rate)(dense_layer_merged1)\n",
    "    dense_layer_merged3 = Dense(units=1, activation='sigmoid')(Dropout6)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=dense_layer_merged3)\n",
    "    return model\n",
    "\n",
    "# Create four separate CNN models\n",
    "input_1 = Input(shape=input_shape)\n",
    "cnn_model_1 = create_cnn_model(input_shape)(input_1)\n",
    "\n",
    "input_2 = Input(shape=input_shape)\n",
    "cnn_model_2 = create_cnn_model(input_shape)(input_2)\n",
    "\n",
    "input_3 = Input(shape=input_shape)\n",
    "cnn_model_3 = create_cnn_model(input_shape)(input_3)\n",
    "\n",
    "input_4 = Input(shape=input_shape)\n",
    "cnn_model_4 = create_cnn_model(input_shape)(input_4)\n",
    "\n",
    "model_multi_fc = run_multiview_model([cnn_model_1, cnn_model_2, cnn_model_3, cnn_model_4],[input_1, input_2, input_3, input_4])\n",
    "model_multi_fc.summary()\n",
    "#model_multi_max = run_multiview_model_latefusionmax([cnn_model_1, cnn_model_2, cnn_model_3, cnn_model_4],[input_1, input_2, input_3, input_4])\n",
    "#model_multi_max.summary()\n",
    "#model_multi_earlymax = run_multiview_model_earlymax([cnn_model_1, cnn_model_2, cnn_model_3, cnn_model_4],[input_1, input_2, input_3, input_4])\n",
    "#model_multi_earlymax.summary()\n",
    "#model_multi_earlyconv = run_multiview_model_earlyconv([cnn_model_1, cnn_model_2, cnn_model_3, cnn_model_4],[input_1, input_2, input_3, input_4])\n",
    "#model_multi_earlyconv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'Equal' defined at (most recent call last):\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/asyncio/base_events.py\", line 1906, in _run_once\n      handle._run()\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_141848/1319341933.py\", line 11, in <module>\n      historymax = model_multi_earlyconv.fit([train_data[:,i,:,:]/max for i in range(4)],train_labels,epochs=num_epochs,batch_size=batch_size,validation_data=([test_data[:,i,:,:] for i in range(4)], test_labels), callbacks=[early_stopping_callback_1])\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/keras/engine/training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/keras/engine/training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/keras/engine/training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/keras/engine/training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/keras/engine/training.py\", line 998, in train_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/keras/engine/training.py\", line 1092, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 605, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/keras/utils/metrics_utils.py\", line 77, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/keras/metrics/base_metric.py\", line 143, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/keras/metrics/base_metric.py\", line 700, in update_state\n      matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/keras/metrics/metrics.py\", line 3605, in binary_accuracy\n      metrics_utils.binary_matches(y_true, y_pred, threshold), axis=-1\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/keras/utils/metrics_utils.py\", line 933, in binary_matches\n      return tf.cast(tf.equal(y_true, y_pred), backend.floatx())\nNode: 'Equal'\nIncompatible shapes: [3200,1] vs. [32,1]\n\t [[{{node Equal}}]] [Op:__inference_train_function_48375]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/home/hanneswarnhofer/ECAP_HiWi_WorkingDirectory/FusionMethodsNotebook.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/hanneswarnhofer/ECAP_HiWi_WorkingDirectory/FusionMethodsNotebook.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m model_multi_earlyconv\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/hanneswarnhofer/ECAP_HiWi_WorkingDirectory/FusionMethodsNotebook.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m early_stopping_callback_1\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mEarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m,patience\u001b[39m=\u001b[39mpatience,verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/hanneswarnhofer/ECAP_HiWi_WorkingDirectory/FusionMethodsNotebook.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m historymax \u001b[39m=\u001b[39m model_multi_earlyconv\u001b[39m.\u001b[39;49mfit([train_data[:,i,:,:]\u001b[39m/\u001b[39;49m\u001b[39mmax\u001b[39;49m \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(\u001b[39m4\u001b[39;49m)],train_labels,epochs\u001b[39m=\u001b[39;49mnum_epochs,batch_size\u001b[39m=\u001b[39;49mbatch_size,validation_data\u001b[39m=\u001b[39;49m([test_data[:,i,:,:] \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(\u001b[39m4\u001b[39;49m)], test_labels), callbacks\u001b[39m=\u001b[39;49m[early_stopping_callback_1])\n",
      "File \u001b[0;32m~/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'Equal' defined at (most recent call last):\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/asyncio/base_events.py\", line 1906, in _run_once\n      handle._run()\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_141848/1319341933.py\", line 11, in <module>\n      historymax = model_multi_earlyconv.fit([train_data[:,i,:,:]/max for i in range(4)],train_labels,epochs=num_epochs,batch_size=batch_size,validation_data=([test_data[:,i,:,:] for i in range(4)], test_labels), callbacks=[early_stopping_callback_1])\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/keras/engine/training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/keras/engine/training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/keras/engine/training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/keras/engine/training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/keras/engine/training.py\", line 998, in train_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/keras/engine/training.py\", line 1092, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 605, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/keras/utils/metrics_utils.py\", line 77, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/keras/metrics/base_metric.py\", line 143, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/keras/metrics/base_metric.py\", line 700, in update_state\n      matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/keras/metrics/metrics.py\", line 3605, in binary_accuracy\n      metrics_utils.binary_matches(y_true, y_pred, threshold), axis=-1\n    File \"/home/hanneswarnhofer/miniconda3/envs/HESSML_ENV2/lib/python3.10/site-packages/keras/utils/metrics_utils.py\", line 933, in binary_matches\n      return tf.cast(tf.equal(y_true, y_pred), backend.floatx())\nNode: 'Equal'\nIncompatible shapes: [3200,1] vs. [32,1]\n\t [[{{node Equal}}]] [Op:__inference_train_function_48375]"
     ]
    }
   ],
   "source": [
    "from keras.losses import BinaryCrossentropy\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "# Create the loss function with from_logits=True\n",
    "loss_fn = BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "# Compile the model using the created loss function\n",
    "model_multi_earlyconv.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "early_stopping_callback_1=tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=patience,verbose=1,mode='min')\n",
    "historymax = model_multi_earlyconv.fit([train_data[:,i,:,:]/max for i in range(4)],train_labels,epochs=num_epochs,batch_size=batch_size,validation_data=([test_data[:,i,:,:] for i in range(4)], test_labels), callbacks=[early_stopping_callback_1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HESSML_ENV2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
